{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "473e2d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce52bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://chatgpt.com/share/68d37473-f210-8000-b586-6a24785e4aff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ee011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astrometry\n",
    "from astropy.io import fits\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.coordinates import Angle\n",
    "from astropy import units as u\n",
    "from astropy.time import Time\n",
    "from photutils.detection import DAOStarFinder\n",
    "import ccdproc as ccdp\n",
    "from ccdproc import CCDData\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from typing import List, Union\n",
    "\n",
    "def prep(\n",
    "    sciframes: List[Union[str, Path]],\n",
    "    masterdir: Union[str, Path],\n",
    "    prepdir: Union[str, Path],\n",
    "    filtername: str,\n",
    "    key_exptime: str = 'exptime'\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Preprocess science frames by subtracting bias, dark, and flat frames.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sciframes : list of str or Path\n",
    "        List of paths to science frame FITS files.\n",
    "    masterdir : str or Path\n",
    "        Directory containing master bias, dark, and flat frames.\n",
    "    prepdir : str or Path\n",
    "        Directory to save preprocessed science frames.\n",
    "    filtername : str\n",
    "        Filter name used for selecting appropriate flat field.\n",
    "    key_exptime : str, optional\n",
    "        Header keyword for exposure time (default is 'exptime').\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    if not sciframes:\n",
    "        logger.warning(\"No science frames found.\")\n",
    "        return\n",
    "\n",
    "    masterdir = Path(masterdir)\n",
    "    if not masterdir.exists():\n",
    "        logger.error(f\"Directory not found: {masterdir}\")\n",
    "        return\n",
    "\n",
    "    prepdir = Path(prepdir)\n",
    "    prepdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    mbiasframes = ccdp.ImageFileCollection(masterdir, glob_include=\"[!._]*.fits\").filter(imagetyp=\"Bias\")\n",
    "    if len(mbiasframes.files) == 0:\n",
    "        logger.error(f\"No master bias found in directory: {masterdir}\")\n",
    "        return\n",
    "\n",
    "    mdarkframes = ccdp.ImageFileCollection(masterdir, glob_include=\"[!._]*.fits\").filter(imagetyp=\"Dark\")\n",
    "    if len(mdarkframes.files) == 0:\n",
    "        logger.error(f\"No master dark found in directory: {masterdir}\")\n",
    "        return\n",
    "\n",
    "    darkexptime = set(mdarkframes.summary[key_exptime])\n",
    "\n",
    "    mflatframes = ccdp.ImageFileCollection(masterdir, glob_include=\"[!._]*.fits\").filter(imagetyp=\"Flat\", filter=filtername)\n",
    "    if len(mflatframes.files) == 0:\n",
    "        logger.error(f\"No master flat (filter={filtername}) found in directory: {masterdir}\")\n",
    "        return\n",
    "\n",
    "    logger.info(f\"{len(sciframes)} science frames found. Preprocessing...\")\n",
    "\n",
    "    for fpath_sci in tqdm(sciframes, desc=\"Processing frames\"):\n",
    "        fpath_sci = Path(fpath_sci)\n",
    "        sci = CCDData.read(fpath_sci, unit='adu')\n",
    "\n",
    "        try:\n",
    "            exptime = float(sci.header.get(key_exptime, np.nan))\n",
    "            obsdate_jd = float(sci.header.get(\"j_date\", \"0\").split()[0])\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Header read error in {fpath_sci}: {e}\")\n",
    "            continue\n",
    "\n",
    "        fpath_psci = prepdir / (fpath_sci.stem + \".p\" + fpath_sci.suffix)\n",
    "\n",
    "        try:\n",
    "            jd_values = mbiasframes.summary.to_pandas()[\"j_date\"].apply(lambda x: float(x.split()[0]))\n",
    "            idx_mbias = (jd_values - obsdate_jd).abs().idxmin()\n",
    "            fpath_mbias = Path(mbiasframes.files_filtered(include_path=True)[idx_mbias])\n",
    "            mbias = CCDData.read(fpath_mbias)\n",
    "\n",
    "            jd_values = mflatframes.summary.to_pandas()[\"j_date\"].apply(lambda x: float(x.split()[0]))\n",
    "            idx_mflat = (jd_values - obsdate_jd).abs().idxmin()\n",
    "            fpath_mflat = Path(mflatframes.files_filtered(include_path=True)[idx_mflat])\n",
    "            mflat = CCDData.read(fpath_mflat)\n",
    "\n",
    "            darkexptime_closest = min(darkexptime, key=lambda x: abs(float(x) - exptime))\n",
    "            mdarkframes_exptime = mdarkframes.filter(**{key_exptime: darkexptime_closest})\n",
    "            jd_values = mdarkframes_exptime.summary.to_pandas()[\"j_date\"].apply(lambda x: float(x.split()[0]))\n",
    "            idx_mdark = (jd_values - obsdate_jd).abs().idxmin()\n",
    "            fpath_mdark = Path(mdarkframes_exptime.files_filtered(include_path=True)[idx_mdark])\n",
    "            mdark = CCDData.read(fpath_mdark)\n",
    "\n",
    "            bsci = ccdp.subtract_bias(sci, mbias)\n",
    "            bdsci = ccdp.subtract_dark(bsci, mdark, exposure_time=key_exptime, exposure_unit=u.second)\n",
    "\n",
    "            bdsci.mask = bdsci.data < 0\n",
    "            bdsci.data = np.nan_to_num(np.clip(bdsci.data, a_min=0., a_max=None), nan=0.0)\n",
    "            bdsci.meta['history'] = f\"Negative values masked. {datetime.now().isoformat()}\"\n",
    "\n",
    "            psci = ccdp.flat_correct(bdsci, mflat)\n",
    "\n",
    "            psci.meta['jd'] = (obsdate_jd, \"Julian date\")\n",
    "            psci.meta['irafname'] = (fpath_sci.stem, \"File Name\")\n",
    "            psci.meta['rdnoise'] = (4.8, \"Readout noise of ccd. (electron/pixel)\")\n",
    "            psci.meta['egain'] = (1, \"Gain factor. (electron/adu)\")\n",
    "            psci.meta['history'] = f'bias, dark, flat corrected with rasapy.calib {datetime.now().isoformat()}\\n' \\\n",
    "                                   f'Master bias: {fpath_mbias.name}\\n' \\\n",
    "                                   f'Master dark: {fpath_mdark.name}\\n' \\\n",
    "                                   f'Master flat: {fpath_mflat.name}'\n",
    "\n",
    "            psci.data = psci.data.astype(np.float32)\n",
    "            psci.write(fpath_psci, overwrite=True)\n",
    "            logger.info(f\"Preprocessed: {fpath_psci}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Processing failed for {fpath_sci}: {e}\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import EarthLocation, AltAz\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "from datetime import datetime\n",
    "import ccdproc\n",
    "import astrometry\n",
    "import sep\n",
    "import numpy as np\n",
    "\n",
    "class RasaLcpyLV1:\n",
    "    \"\"\"\n",
    "    Class for Level-1 processing of RASA lcpy KL4040 science frames.\n",
    "\n",
    "    Provides methods to solve and update WCS, and to apply bias, dark, and flat corrections.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_file: str = None):\n",
    "        \"\"\"\n",
    "        Configure logging to console and optional file.\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler()\n",
    "        handler.setFormatter(logging.Formatter(\"%(asctime)s [%(levelname)s] %(message)s\"))\n",
    "        self.logger.addHandler(handler)\n",
    "\n",
    "        if log_file:\n",
    "            file_h = logging.FileHandler(log_file)\n",
    "            file_h.setFormatter(handler.formatter)\n",
    "            self.logger.addHandler(file_h)\n",
    "            \n",
    "    def update_wcs(self, fpath_fits, outdir, return_fpath=True):\n",
    "        \"\"\"\n",
    "        Solve for WCS using astrometry.net and update FITS header accordingly.\n",
    "        \"\"\"\n",
    "        fpath_fits = Path(fpath_fits)\n",
    "        outdir = Path(outdir)\n",
    "\n",
    "        try:\n",
    "            sci = ccdproc.CCDData.read(fpath_fits)\n",
    "        except FileNotFoundError:\n",
    "            self.logger.error(f\"File not found: {fpath_fits}\")\n",
    "            return\n",
    "        except ValueError:\n",
    "            sci = ccdproc.CCDData.read(fpath_fits, unit=\"adu\")\n",
    "            self.logger.warning(f\"BUNIT undefined; defaulting to 'adu': {fpath_fits}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error reading FITS: {e}\")\n",
    "            return\n",
    "\n",
    "        # detect stars\n",
    "        sci.data = sci.data.astype(np.float32)\n",
    "        bkg = sep.Background(sci.data)\n",
    "        objs = sep.extract(sci.data - bkg.back(), thresh=3.0 * bkg.globalrms, minarea=5)\n",
    "        bright = objs[np.argsort(objs['flux'])[::-1][:50]]\n",
    "        coords = np.vstack((bright['x'], bright['y'])).T\n",
    "\n",
    "        # solve WCS\n",
    "        with astrometry.Solver(\n",
    "            astrometry.series_4100.index_files(cache_directory=\"astrometry_cache\", scales={8,9,10})\n",
    "        ) as solver:\n",
    "            sol = solver.solve(\n",
    "                stars=coords,\n",
    "                size_hint=astrometry.SizeHint(lower_arcsec_per_pixel=2.95, upper_arcsec_per_pixel=3.00),\n",
    "                position_hint=astrometry.PositionHint(\n",
    "                    ra_deg=sci.header[\"RA\"], dec_deg=sci.header[\"DEC\"], radius_deg=5.0\n",
    "                ),\n",
    "                solution_parameters=astrometry.SolutionParameters(\n",
    "                    logodds_callback=lambda l: astrometry.Action.STOP if len(l)>=10 else astrometry.Action.CONTINUE\n",
    "                )\n",
    "            )\n",
    "            if sol.has_match():\n",
    "                best = sol.best_match()\n",
    "                self.logger.info(f\"WCS match: RA={best.center_ra_deg:.5f}, DEC={best.center_dec_deg:.5f}, scale={best.scale_arcsec_per_pixel:.3f}\" )\n",
    "                sci.wcs = best.astropy_wcs()\n",
    "                hdr = best.astropy_wcs().to_header(relax=False)\n",
    "                sci.header.extend(hdr, update=True)\n",
    "                sci.header['PIXSCALE'] = (best.scale_arcsec_per_pixel, \"arcsec/pixel\")\n",
    "                sci.header['HISTORY'] = f\"({datetime.now().isoformat()}) WCS updated\"\n",
    "            else:\n",
    "                self.logger.warning(\"No WCS solution found.\")\n",
    "\n",
    "        # compute center coords\n",
    "        cen = (sci.header['NAXIS1']//2, sci.header['NAXIS2']//2)\n",
    "        sky = sci.wcs.pixel_to_world(*cen)\n",
    "        loc = EarthLocation(lat=sci.header['LAT']*u.deg, lon=sci.header['LON']*u.deg, height=sci.header['ELEV']*u.km)\n",
    "        altaz = sky.transform_to(AltAz(obstime=Time(sci.header['JD'], format='jd'), location=loc))\n",
    "        sci.header['RACEN'] = (sky.ra.value, \"deg center RA\")\n",
    "        sci.header['DECCEN'] = (sky.dec.value, \"deg center DEC\")\n",
    "        sci.header['ALTCEN'] = (altaz.alt.value, \"deg center Alt\")\n",
    "        sci.header['AZCEN'] = (altaz.az.value, \"deg center Az\")\n",
    "\n",
    "        outpath = Path(outdir)/ (fpath_fits.stem + \".wcs\" + fpath_fits.suffix)\n",
    "        fits.PrimaryHDU(data=sci.data, header=sci.header).writeto(outpath, overwrite=True)\n",
    "        self.logger.info(f\"WCS updated: {outpath.name}\")\n",
    "        if return_fpath:\n",
    "            return outpath\n",
    "\n",
    "    def preprocessing(self, fpath_fits, outdir, masterdir, return_fpath=True):\n",
    "        \"\"\"\n",
    "        Subtract bias, dark, mask bad pixels, and flat-correct a science frame.\n",
    "        \"\"\"\n",
    "        fpath_fits = Path(fpath_fits)\n",
    "        outdir = Path(outdir)\n",
    "        masterdir = Path(masterdir)\n",
    "        outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            sci = ccdproc.CCDData.read(fpath_fits)\n",
    "        except FileNotFoundError:\n",
    "            self.logger.error(f\"File not found: {fpath_fits}\")\n",
    "            return\n",
    "        except ValueError:\n",
    "            sci = ccdproc.CCDData.read(fpath_fits, unit=\"adu\")\n",
    "            self.logger.warning(f\"BUNIT undefined; defaulting to 'adu': {fpath_fits}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error reading FITS: {e}\")\n",
    "            return\n",
    "\n",
    "        # load masters\n",
    "        mbias = self._select_master(masterdir, 'BIAS', sci.header['JD'])\n",
    "        mdark = self._select_master(masterdir, 'DARK', sci.header['JD'], sci.header['EXPTIME'])\n",
    "        mflat = self._select_master(masterdir, 'FLAT', sci.header['JD'])\n",
    "\n",
    "        # bias\n",
    "        bsci = ccdproc.subtract_bias(sci, mbias)\n",
    "        bsci.meta['BIASCORR'] = True\n",
    "        self.logger.info(\"Bias subtracted.\")\n",
    "        # dark\n",
    "        bdsci = ccdproc.subtract_dark(bsci, mdark, exposure_time=\"EXPTIME\", exposure_unit=u.second)\n",
    "        bdsci.meta['DARKCORR'] = True\n",
    "        self.logger.info(\"Dark subtracted.\")\n",
    "        # mask\n",
    "        bdsci.mask = bdsci.data < 0\n",
    "        bdsci.data = np.nan_to_num(np.clip(bdsci.data, 0, None))\n",
    "        self.logger.info(\"Bad pixels masked.\")\n",
    "        # flat\n",
    "        psci = ccdproc.flat_correct(bdsci, mflat)\n",
    "        psci.meta['FLATCORR'] = True\n",
    "        self.logger.info(\"Flat corrected.\")\n",
    "\n",
    "        # build output name\n",
    "        rac = int(round(psci.header['RACEN']))\n",
    "        dec = int(round(psci.header['DECCEN']))\n",
    "        pm = 'p' if dec >= 0 else 'n'\n",
    "        exp = int(round(psci.header['EXPTIME']))\n",
    "        obst = Time(psci.header['DATE-OBS']).strftime(\"%Y%m%d%H%M%S\")\n",
    "        outname = f\"kl4040.sci.{rac:03d}.{pm}{abs(dec):02d}.{exp:03d}.{obst}.fits\"\n",
    "        outpath = outdir / outname\n",
    "        fits.PrimaryHDU(data=psci.data, header=psci.header).writeto(outpath, overwrite=True)\n",
    "        self.logger.info(f\"Preprocessing complete: {outname}\")\n",
    "        if return_fpath:\n",
    "            return outpath\n",
    "\n",
    "    def _select_master(self, masterdir, imagetyp, jd_target, exptime=None):\n",
    "        \"\"\"\n",
    "        Helper to select the closest master frame by JD (and exposure time if given).\n",
    "        \"\"\"\n",
    "        coll = ccdproc.ImageFileCollection(masterdir, glob_include=\"*.fits\").filter(imagetyp=imagetyp)\n",
    "        df = coll.summary.to_pandas()\n",
    "        df['jd'] = df.get('jd', df.get('JD')).astype(float)\n",
    "        df['diff'] = (df['jd'] - jd_target).abs()\n",
    "        if exptime is not None and 'exptime' in df.columns:\n",
    "            df = df[df['exptime'].astype(float) == float(exptime)]\n",
    "        idx = df['diff'].idxmin()\n",
    "        return ccdproc.CCDData.read(Path(coll.files_filtered(include_path=True)[idx]), unit='adu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a850fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import EarthLocation, AltAz\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "from datetime import datetime\n",
    "import ccdproc\n",
    "import astrometry\n",
    "import sep\n",
    "import numpy as np\n",
    "\n",
    "class RasaLcpyLV1:\n",
    "    \n",
    "    \"\"\"\n",
    "    Class for updating Level-1 (pre-processed) FITS headers in the RASA lcpy KL4040 data pipeline.\n",
    "\n",
    "    This encapsulates metadata verification, enrichment (coordinate transforms, elongations),\n",
    "    and logging into a reusable component suitable for CLI or workflow integration.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_file: str = None):\n",
    "        \"\"\"\n",
    "        Initialize logger. If log_file is provided, logs are written to that file as well as stdout.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        log_file : str, optional\n",
    "            Path to a log file to append processing records.\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler()\n",
    "        handler.setFormatter(logging.Formatter(\"%(asctime)s [%(levelname)s] %(message)s\"))\n",
    "        self.logger.addHandler(handler)\n",
    "\n",
    "        if log_file:\n",
    "            file_h = logging.FileHandler(log_file)\n",
    "            file_h.setFormatter(handler.formatter)\n",
    "            self.logger.addHandler(file_h)\n",
    "            \n",
    "    def update_wcs(self, fpath_fits, outdir, return_fpath=True):\n",
    "    \n",
    "        fpath_fits = Path(fpath_fits)\n",
    "        outdir = Path(outdir)\n",
    "\n",
    "        try:\n",
    "            sci = ccdproc.CCDData.read(fpath_fits)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"File Not Found: {fpath_fits}\")\n",
    "            \n",
    "        except ValueError:\n",
    "            sci = ccdproc.CCDData.read(fpath_fits, unit=\"adu\")\n",
    "            print(f\"Warning. the BUNIT is undefined. Use BUNIT='adu': {fpath_fits}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read FITS file: {e}\")\n",
    "\n",
    "        # Source detection (sep)\n",
    "        sci.data         = sci.data.astype(np.float32)\n",
    "        bkg              = sep.Background(sci.data) \n",
    "        objects          = sep.extract(sci.data - bkg.back(), thresh=3.0*bkg.globalrms, minarea=5)\n",
    "        objects_bright   = objects[np.argsort(objects['flux'])[::-1][:50]] # Brightest 50 stars\n",
    "        xcoords, ycoords = objects_bright['x'], objects_bright['y']\n",
    "        coords           = np.vstack((xcoords, ycoords)).T\n",
    "\n",
    "        # Solve WCS (astrometry.Solver)\n",
    "        with astrometry.Solver(\n",
    "                astrometry.series_4100.index_files(\n",
    "                    cache_directory=\"astrometry_cache\",\n",
    "                    scales={8, 9, 10}\n",
    "                    # Series scales. Each scale has different skymark diameter. \n",
    "                    # Recommend 0.1x - 1.0x of FOV diameter.\n",
    "                    # For detail, see https://pypi.org/project/astrometry/#choosing-series\n",
    "                )\n",
    "            ) as solver:\n",
    "\n",
    "                solution = solver.solve(\n",
    "                    stars=coords,\n",
    "                    size_hint=astrometry.SizeHint(\n",
    "                        lower_arcsec_per_pixel=2.95,\n",
    "                        upper_arcsec_per_pixel=3.00, # kl4040 pixel scale 2.97\"\n",
    "                    ),\n",
    "                    position_hint=astrometry.PositionHint(\n",
    "                        ra_deg=sci.header[\"RA\"],\n",
    "                        dec_deg=sci.header[\"DEC\"],\n",
    "                        radius_deg=5.0,\n",
    "                    ),\n",
    "                    solution_parameters=astrometry.SolutionParameters(\n",
    "                        logodds_callback=lambda l: (\n",
    "                            astrometry.Action.STOP if len(l) >= 10 else astrometry.Action.CONTINUE\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                # Solution found\n",
    "                if solution.has_match():\n",
    "                    \n",
    "                    best = solution.best_match()\n",
    "                    print(f\"\\tWCS matched: RA={best.center_ra_deg:.5f} deg, DEC={best.center_dec_deg:.5f} deg, scale={best.scale_arcsec_per_pixel:.3f} \\\"/pix\")\n",
    "\n",
    "                    # Update wcs information into header\n",
    "                    sci.wcs = best.astropy_wcs()\n",
    "\n",
    "                    hdr_wcs = best.astropy_wcs().to_header(relax=False)\n",
    "                    sci.header.extend(hdr_wcs, update=True)\n",
    "                    sci.header['PIXSCALE'] =(best.scale_arcsec_per_pixel, \"[arcsec/pixel] Pixel Scale\")\n",
    "                    sci.header[\"HISTORY\"]  = f\"({datetime.now().isoformat()}) WCS updated. (astrometry.Solver)\"\n",
    "                    \n",
    "                else:\n",
    "                    print(\"\\tSkipping: No WCS match found.\")\n",
    "                    \n",
    "        # Center pixel coordiates based on WCS\n",
    "        xycoord_cenpix  = sci.header[\"NAXIS1\"]//2, sci.header[\"NAXIS2\"]//2 # Center pixel\n",
    "        skycoord_cenpix = sci.wcs.pixel_to_world(*xycoord_cenpix) # Sky coordinate of center pixel\n",
    "        location        = EarthLocation(lat=sci.header[\"LAT\"]*u.deg, lon=sci.header[\"LON\"]*u.deg, height=sci.header[\"ELEV\"]*u.km)\n",
    "        obstime         = Time(sci.header['JD'], format='jd')\n",
    "        altaz_frame     = AltAz(obstime=obstime, location=location)\n",
    "        altaz_cenpix    = skycoord_cenpix.transform_to(altaz_frame)\n",
    "\n",
    "        # Update header information\n",
    "        sci.header[\"RACEN\"]  = (skycoord_cenpix.ra.value, \"[deg] Right Ascension of center pixel\")\n",
    "        sci.header[\"DECCEN\"] = (skycoord_cenpix.dec.value, \"[deg] Declination of center pixel\")\n",
    "        sci.header[\"ALTCEN\"] = (altaz_cenpix.alt.value, \"[deg] Altitude of center pixel\")\n",
    "        sci.header[\"AZCEN\"]  = (altaz_cenpix.az.value, \"[deg] Azimuth of center pixel\")\n",
    "\n",
    "        hdul_updated = fits.PrimaryHDU(data=sci.data, header=sci.header)\n",
    "        fpath_fits_updated = outdir / (fpath_fits.stem + \".wcs\" + fpath_fits.suffix)\n",
    "        hdul_updated.writeto(fpath_fits_updated, overwrite=True)\n",
    "        print(f\"WCS updated. {fpath_fits.name} -> {fpath_fits_updated.name}\")\n",
    "        \n",
    "        if return_fpath:\n",
    "            return fpath_fits_updated\n",
    "        \n",
    "    \n",
    "    def preprocessing(self, fpath_fits, outdir, masterdir, return_fpath=True):\n",
    "\n",
    "        fpath_fits = Path(fpath_fits)\n",
    "        masterdir  = Path(masterdir)\n",
    "        outdir     = Path(outdir)\n",
    "        outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        try:\n",
    "            sci = ccdproc.CCDData.read(fpath_fits)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"File Not Found: {fpath_fits}\")\n",
    "            \n",
    "        except ValueError:\n",
    "            sci = ccdproc.CCDData.read(fpath_fits, unit=\"adu\")\n",
    "            print(f\"Warning. the BUNIT is undefined. Use BUNIT='adu': {fpath_fits}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read FITS file: {e}\")\n",
    "\n",
    "        mbiasframes = ccdproc.ImageFileCollection(masterdir, glob_include=\"[!._]*.fits\").filter(imagetyp=\"BIAS\")\n",
    "        if len(mbiasframes.files) == 0:\n",
    "            print(f\"No master bias found in the directory: {masterdir}\")\n",
    "            return\n",
    "            \n",
    "        mdarkframes = ccdproc.ImageFileCollection(masterdir, glob_include=\"[!._]*.fits\").filter(imagetyp=\"DARK\")\n",
    "        if len(mdarkframes.files) == 0:\n",
    "            print(f\"No master dark found in the directory: {masterdir}\")\n",
    "            return\n",
    "\n",
    "        mflatframes = ccdproc.ImageFileCollection(masterdir, glob_include=\"[!._]*.fits\").filter(imagetyp=\"FLAT\")\n",
    "        if len(mflatframes.files) == 0:\n",
    "            print(f\"No master flat found in the directory: {masterdir}\")\n",
    "            return\n",
    "            \n",
    "        # Load mbias (Observed closest to science frame)\n",
    "        jd_mbiases          = mbiasframes.summary.to_pandas()[\"jd\"]\n",
    "        idx_mbias           = (jd_mbiases - sci.header[\"JD\"]).abs().idxmin()\n",
    "        fpath_mbias         = Path(mbiasframes.files_filtered(include_path=True)[idx_mbias])\n",
    "        mbias               = ccdproc.CCDData.read(fpath_mbias)\n",
    "\n",
    "        # Load the master dark frame (Observed and exposured closest to science frame)\n",
    "        darkexptime         = set(mdarkframes.summary[\"exptime\"])\n",
    "        darkexptime_closest = min(darkexptime, key=lambda x: abs(float(x) - sci.header[\"EXPTIME\"]))\n",
    "        mdarkframes_exptime = mdarkframes.filter(**{\"EXPTIME\": darkexptime_closest})\n",
    "        jd_values           = mdarkframes_exptime.summary.to_pandas()[\"jd\"]\n",
    "        idx_mdark           = (jd_values - sci.header[\"JD\"]).abs().idxmin()\n",
    "        fpath_mdark         = Path(mdarkframes_exptime.files_filtered(include_path=True)[idx_mdark])\n",
    "        mdark               = ccdproc.CCDData.read(fpath_mdark)\n",
    "\n",
    "        # Load master flat (Close to the observation time)\n",
    "        jd_values            = mflatframes.summary.to_pandas()[\"jd\"]\n",
    "        idx_mflat            = (jd_values - sci.header[\"JD\"]).abs().idxmin()\n",
    "        fpath_mflat          = Path(mflatframes.files_filtered(include_path=True)[idx_mflat])\n",
    "        mflat                = ccdproc.CCDData.read(fpath_mflat)\n",
    "\n",
    "        # Subtract bias\n",
    "        bsci = ccdproc.subtract_bias(sci, mbias)\n",
    "        bsci.meta[\"BIASCORR\"] = True\n",
    "        bsci.meta[\"HISTORY\"] = f\"({datetime.now().isoformat()}) Bias subtracted.\"\n",
    "        bsci.meta[\"HISTORY\"] = f'Master bias: {fpath_mbias.name}'\n",
    "\n",
    "        # Subtract dark\n",
    "        bdsci = ccdproc.subtract_dark(bsci, mdark, exposure_time=\"EXPTIME\", exposure_unit=u.second)\n",
    "        bdsci.meta[\"DARKCORR\"] = True\n",
    "        bdsci.meta[\"HISTORY\"] = f\"({datetime.now().isoformat()}) Dark subtracted.\"\n",
    "        bdsci.meta[\"HISTORY\"] = f'Master dark: {fpath_mdark.name}'\n",
    "\n",
    "        # Bad pixel masking\n",
    "        bdsci.mask = bdsci.data < 0\n",
    "        bdsci.data = np.nan_to_num(np.clip(bdsci.data, a_min=0., a_max=None), nan=0.0)\n",
    "        bdsci.meta['HISTORY'] = f\"({datetime.now().isoformat()}) Negative values masked.\"\n",
    "\n",
    "        # Correct Flat\n",
    "        psci = ccdproc.flat_correct(bdsci, mflat)\n",
    "        if mflat.mask is not None:\n",
    "            psci.mask = psci.mask * mflat.mask\n",
    "        psci.meta[\"FLATCORR\"] = True\n",
    "        psci.meta[\"HISTORY\"] = f\"({datetime.now().isoformat()}) Flat corrected.\"\n",
    "        psci.meta[\"HISTORY\"] = f'Master flat: {fpath_mflat.name}'\n",
    "\n",
    "        #### Bad pixel masking (strange flat values, TBA)\n",
    "\n",
    "        # Updated file name\n",
    "        racen_int   = int(round(psci.header['RACEN']))\n",
    "        deccen_int  = int(round(psci.header['DECCEN']))\n",
    "        deccen_pm   = \"p\" if deccen_int >=0. else \"n\"\n",
    "        exptime_int = int(round(psci.header[\"EXPTIME\"]))\n",
    "        obstime     = Time(psci.header[\"DATE-OBS\"]).strftime(\"%Y%m%d%H%M%S\")\n",
    "        fpath_fits_updated = outdir / f\"kl4040.sci.{racen_int:03d}.{deccen_pm}{abs(deccen_int):02d}.{exptime_int:03d}.{obstime}.fits\"\n",
    "\n",
    "        psci.meta[\"OBJECT\"] = fpath_fits_updated.stem\n",
    "\n",
    "        hdul_updated = fits.PrimaryHDU(data=psci.data, header=psci.header)\n",
    "        hdul_updated.writeto(fpath_fits_updated, overwrite=True)\n",
    "        print(f\"Preprocessing: {fpath_fits} -> {fpath_fits_updated}\")\n",
    "\n",
    "        if return_fpath:\n",
    "            return fpath_fits_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9cd4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import EarthLocation, AltAz\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "from datetime import datetime\n",
    "import ccdproc\n",
    "import astrometry\n",
    "import sep\n",
    "import numpy as np\n",
    "\n",
    "class RasaLcpyLV1:\n",
    "    \"\"\"\n",
    "    Class for updating Level-1 (pre-processed) FITS headers in the RASA lcpy KL4040 data pipeline.\n",
    "\n",
    "    This encapsulates metadata verification, enrichment (coordinate transforms, elongations),\n",
    "    and logging into a reusable component suitable for CLI or workflow integration.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_file: str = None):\n",
    "        \"\"\"\n",
    "        Initialize logger. If log_file is provided, logs are written to that file as well as stdout.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        log_file : str, optional\n",
    "            Path to a log file to append processing records.\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler()\n",
    "        handler.setFormatter(logging.Formatter(\"%(asctime)s [%(levelname)s] %(message)s\"))\n",
    "        self.logger.addHandler(handler)\n",
    "\n",
    "        if log_file:\n",
    "            file_h = logging.FileHandler(log_file)\n",
    "            file_h.setFormatter(handler.formatter)\n",
    "            self.logger.addHandler(file_h)\n",
    "            \n",
    "    def update_wcs(self, fpath_fits, outdir, return_fpath=True):\n",
    "        \"\"\"Solve and update WCS information in a Level-1 FITS file.\"\"\"\n",
    "        fpath_fits = Path(fpath_fits)\n",
    "        outdir = Path(outdir)\n",
    "\n",
    "        try:\n",
    "            sci = ccdproc.CCDData.read(fpath_fits)\n",
    "        except FileNotFoundError:\n",
    "            self.logger.error(f\"File Not Found: {fpath_fits}\")\n",
    "            return\n",
    "        except ValueError:\n",
    "            sci = ccdproc.CCDData.read(fpath_fits, unit=\"adu\")\n",
    "            self.logger.warning(f\"BUNIT undefined, using 'adu': {fpath_fits}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to read FITS file: {e}\")\n",
    "            return\n",
    "\n",
    "        # Source detection (sep)\n",
    "        sci.data = sci.data.astype(np.float32)\n",
    "        bkg = sep.Background(sci.data)\n",
    "        objects = sep.extract(sci.data - bkg.back(), thresh=3.0 * bkg.globalrms, minarea=5)\n",
    "        objects_bright = objects[np.argsort(objects['flux'])[::-1][:50]]\n",
    "        coords = np.vstack((objects_bright['x'], objects_bright['y'])).T\n",
    "\n",
    "        with astrometry.Solver(\n",
    "                astrometry.series_4100.index_files(\n",
    "                    cache_directory=\"astrometry_cache\",\n",
    "                    scales={8, 9, 10}\n",
    "                )\n",
    "            ) as solver:\n",
    "\n",
    "            solution = solver.solve(\n",
    "                stars=coords,\n",
    "                size_hint=astrometry.SizeHint(\n",
    "                    lower_arcsec_per_pixel=2.95,\n",
    "                    upper_arcsec_per_pixel=3.00,\n",
    "                ),\n",
    "                position_hint=astrometry.PositionHint(\n",
    "                    ra_deg=sci.header[\"RA\"],\n",
    "                    dec_deg=sci.header[\"DEC\"],\n",
    "                    radius_deg=5.0,\n",
    "                ),\n",
    "                solution_parameters=astrometry.SolutionParameters(\n",
    "                    logodds_callback=lambda l: (\n",
    "                        astrometry.Action.STOP if len(l) >= 10 else astrometry.Action.CONTINUE\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if solution.has_match():\n",
    "                best = solution.best_match()\n",
    "                self.logger.info(\n",
    "                    f\"WCS matched: RA={best.center_ra_deg:.5f} deg, DEC={best.center_dec_deg:.5f} deg, \"\n",
    "                    f\"scale={best.scale_arcsec_per_pixel:.3f} \\\"/pix\"\n",
    "                )\n",
    "                sci.wcs = best.astropy_wcs()\n",
    "                hdr_wcs = best.astropy_wcs().to_header(relax=False)\n",
    "                sci.header.extend(hdr_wcs, update=True)\n",
    "                sci.header['PIXSCALE'] = (best.scale_arcsec_per_pixel, \"[arcsec/pixel] Pixel Scale\")\n",
    "                sci.header['HISTORY'] = f\"({datetime.now().isoformat()}) WCS updated. (astrometry.Solver)\"\n",
    "            else:\n",
    "                self.logger.warning(\"No WCS match found; skipping update.\")\n",
    "\n",
    "        # Center pixel coordinates\n",
    "        xy_cen = sci.header['NAXIS1'] // 2, sci.header['NAXIS2'] // 2\n",
    "        sky_cen = sci.wcs.pixel_to_world(*xy_cen)\n",
    "        loc = EarthLocation(lat=sci.header['LAT']*u.deg,\n",
    "                            lon=sci.header['LON']*u.deg,\n",
    "                            height=sci.header['ELEV']*u.km)\n",
    "        obstime = Time(sci.header['JD'], format='jd')\n",
    "        altaz = sky_cen.transform_to(AltAz(obstime=obstime, location=loc))\n",
    "\n",
    "        sci.header['RACEN'] = (sky_cen.ra.value, \"[deg] RA of center pixel\")\n",
    "        sci.header['DECCEN'] = (sky_cen.dec.value, \"[deg] Dec of center pixel\")\n",
    "        sci.header['ALTCEN'] = (altaz.alt.value, \"[deg] Alt of center pixel\")\n",
    "        sci.header['AZCEN'] = (altaz.az.value, \"[deg] Az of center pixel\")\n",
    "\n",
    "        hdul = fits.PrimaryHDU(data=sci.data, header=sci.header)\n",
    "        outpath = outdir / (fpath_fits.stem + \".wcs\" + fpath_fits.suffix)\n",
    "        hdul.writeto(outpath, overwrite=True)\n",
    "        self.logger.info(f\"WCS updated: {fpath_fits.name} -> {outpath.name}\")\n",
    "\n",
    "        if return_fpath:\n",
    "            return outpath\n",
    "\n",
    "    def preprocessing(self, fpath_fits, outdir, masterdir, return_fpath=True):\n",
    "        \"\"\"Apply bias, dark, and flat corrections to a science frame.\"\"\"\n",
    "        fpath_fits = Path(fpath_fits)\n",
    "        outdir = Path(outdir)\n",
    "        masterdir = Path(masterdir)\n",
    "        outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        try:\n",
    "            sci = ccdproc.CCDData.read(fpath_fits)\n",
    "        except FileNotFoundError:\n",
    "            self.logger.error(f\"File Not Found: {fpath_fits}\")\n",
    "            return\n",
    "        except ValueError:\n",
    "            sci = ccdproc.CCDData.read(fpath_fits, unit=\"adu\")\n",
    "            self.logger.warning(f\"BUNIT undefined, using 'adu': {fpath_fits}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to read FITS file: {e}\")\n",
    "            return\n",
    "\n",
    "        # Load masters\n",
    "        mbias_frames = ccdproc.ImageFileCollection(masterdir, glob_include=\"*.fits\").filter(imagetyp=\"BIAS\")\n",
    "        mdark_frames = ccdproc.ImageFileCollection(masterdir, glob_include=\"*.fits\").filter(imagetyp=\"DARK\")\n",
    "        mflat_frames = ccdproc.ImageFileCollection(masterdir, glob_include=\"*.fits\").filter(imagetyp=\"FLAT\")\n",
    "\n",
    "        if not mbias_frames.files:\n",
    "            self.logger.error(f\"No master bias in {masterdir}\")\n",
    "            return\n",
    "        if not mdark_frames.files:\n",
    "            self.logger.error(f\"No master dark in {masterdir}\")\n",
    "            return\n",
    "        if not mflat_frames.files:\n",
    "            self.logger.error(f\"No master flat in {masterdir}\")\n",
    "            return\n",
    "\n",
    "        # Bias subtraction\n",
    "        jd_vals = mbias_frames.summary.to_pandas()[\"jd\"].astype(float)\n",
    "        idx = (abs(jd_vals - sci.header['JD'])).idxmin()\n",
    "        mbias = ccdproc.CCDData.read(Path(mbias_frames.files_filtered(include_path=True)[idx]), unit=\"adu\")\n",
    "        bsci = ccdproc.subtract_bias(sci, mbias)\n",
    "        bsci.meta['BIASCORR'] = True\n",
    "        bsci.meta['HISTORY'] = f\"({datetime.now().isoformat()}) Bias subtracted.\"\n",
    "        self.logger.info(f\"Bias subtracted using {Path(mbias_frames.files_filtered(include_path=True)[idx]).name}\")\n",
    "\n",
    "        # Dark subtraction\n",
    "        exp_list = set(mdark_frames.summary['exptime'])\n",
    "        closest_exp = min(exp_list, key=lambda x: abs(float(x) - sci.header['EXPTIME']))\n",
    "        drange = mdark_frames.filter(**{\"EXPTIME\": closest_exp})\n",
    "        jd_vals = drange.summary.to_pandas()['jd'].astype(float)\n",
    "        idxd = (abs(jd_vals - sci.header['JD'])).idxmin()\n",
    "        mdark = ccdproc.CCDData.read(Path(drange.files_filtered(include_path=True)[idxd]), unit=\"adu\")\n",
    "        bdsci = ccdproc.subtract_dark(bsci, mdark, exposure_time=\"EXPTIME\", exposure_unit=u.second)\n",
    "        bdsci.meta['DARKCORR'] = True\n",
    "        bdsci.meta['HISTORY'] = f\"({datetime.now().isoformat()}) Dark subtracted.\"\n",
    "        self.logger.info(f\"Dark subtracted using {Path(drange.files_filtered(include_path=True)[idxd]).name}\")\n",
    "\n",
    "        # Bad pixel masking\n",
    "        bdsci.mask = bdsci.data < 0\n",
    "        bdsci.data = np.nan_to_num(np.clip(bdsci.data, a_min=0., a_max=None), nan=0.0)\n",
    "        bdsci.meta['HISTORY'] = f\"({datetime.now().isoformat()}) Negative values masked.\"\n",
    "        self.logger.info(\"Bad pixels masked.\")\n",
    "\n",
    "        # Flat correction\n",
    "        jd_vals = mflat_frames.summary.to_pandas()['jd'].astype(float)\n",
    "        idxf = (abs(jd_vals - sci.header['JD'])).idxmin()\n",
    "        mflat = ccdproc.CCDData.read(Path(mflat_frames.files_filtered(include_path=True)[idxf]), unit=\"adu\")\n",
    "        psci = ccdproc.flat_correct(bdsci, mflat)\n",
    "        if mflat.mask is not None:\n",
    "            psci.mask = psci.mask * mflat.mask\n",
    "        psci.meta['FLATCORR'] = True\n",
    "        psci.meta['HISTORY'] = f\"({datetime.now().isoformat()}) Flat corrected.\"  \n",
    "        self.logger.info(f\"Flat corrected using {Path(mflat_frames.files_filtered(include_path=True)[idxf]).name}\")\n",
    "\n",
    "        # Construct output filename\n",
    "        rac = int(round(psci.header['RACEN']))\n",
    "        dec = int(round(psci.header['DECCEN']))\n",
    "        pm = 'p' if dec >= 0 else 'n'\n",
    "        exp = int(round(psci.header['EXPTIME']))\n",
    "        obst = Time(psci.header['DATE-OBS']).strftime(\"%Y%m%d%H%M%S\")\n",
    "        outname = f\"kl4040.sci.{rac:03d}.{pm}{abs(dec):02d}.{exp:03d}.{obst}.fits\"\n",
    "        outpath = outdir / outname\n",
    "\n",
    "        psci.meta['OBJECT'] = outpath.stem\n",
    "        fits.PrimaryHDU(data=psci.data, header=psci.header).writeto(outpath, overwrite=True)\n",
    "        self.logger.info(f\"Preprocessing complete: {fpath_fits.name} -> {outname}\")\n",
    "\n",
    "        if return_fpath:\n",
    "            return outpath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170fe706",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.wcs import FITSFixedWarning\n",
    "import astropy.units as u\n",
    "from astropy.nddata import CCDData\n",
    "from astropy.stats import mad_std\n",
    "import ccdproc as ccdp\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import _funcs as funcs\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FITSFixedWarning)\n",
    "\n",
    "def make_mbias(biasframes, masterdir):\n",
    "    \n",
    "    \"\"\"\n",
    "    Combine multiple bias frames into a master bias frame and save the result.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    biasframes : list of str\n",
    "        List of file paths to the individual bias frames to be combined.\n",
    "    masterdir : str or Path\n",
    "        Directory where the master bias frame will be saved.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        The function saves the combined master bias frame as a FITS file in the specified directory.\n",
    "        \n",
    "    Notes:\n",
    "    ------\n",
    "    - The function checks if any bias frames are provided. If none are found, it exits without processing.\n",
    "    - The observation date is extracted from the header of the first bias frame and used to name the output file.\n",
    "    - The bias frames are combined using a median method with sigma clipping to remove outliers.\n",
    "    - Metadata is added to the resulting master bias frame, including information about the combination process and the input files.\n",
    "    - The output file is saved in the specified directory with a name in the format `rasa.bias.<obsdate>.comb.fits`.\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> biasframes = [\"bias1.fits\", \"bias2.fits\", \"bias3.fits\"]\n",
    "    >>> mbiasdir = \"/path/to/output/directory\"\n",
    "    >>> make_mbias(biasframes, mbiasdir)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\"\"\\n================================\n",
    "Master Bias\n",
    "================================\"\"\")\n",
    "    \n",
    "    masterdir = Path(masterdir)\n",
    "    masterdir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Check if bias frames exist.\n",
    "    if len(biasframes) == 0:\n",
    "        print(f\"No bias frames found.\")\n",
    "        return\n",
    "    \n",
    "    # Metatdata (first frame)\n",
    "    meta_bias  = fits.getheader(biasframes[0])\n",
    "    \n",
    "    # Extract observation date.\n",
    "    # obsdate_jd = meta_bias[\"JD\"]\n",
    "    obsdate    = meta_bias[\"OBSDATE\"] # YYYYMMDD\n",
    "    \n",
    "    # Output file name \n",
    "    fpath_mbias = masterdir/(f\"kl4040.bias.comb.{obsdate}.fits\")\n",
    "    \n",
    "    print(f\"\\nobs-date: {obsdate}\")\n",
    "    print(f\"\\n{len(biasframes)} bias frames have been found. Combining master frame...\")\n",
    "    \n",
    "    mbias = ccdp.combine(\n",
    "        biasframes,\n",
    "        method='median',\n",
    "        # unit='adu',\n",
    "        sigma_clip=True,\n",
    "        sigma_clip_low_thresh=5,\n",
    "        sigma_clip_high_thresh=5,\n",
    "        sigma_clip_func=np.ma.median,\n",
    "        sigma_clip_dev_func=mad_std,\n",
    "        mem_limit=500e6,\n",
    "        dtype=np.float32\n",
    "        )\n",
    "    \n",
    "    # Additional metadata\n",
    "    mbias.meta['COMBINED'] = True\n",
    "    mbias.meta[\"NCOMBINE\"] = (len(biasframes), \"Number of combined frames\")\n",
    "    # mbias.meta['jd']       = (obsdate_jd, \"Julian date\")\n",
    "    mbias.meta['IMAGETYP'] = \"BIAS\"\n",
    "    mbias.meta['OBJECT']   = fpath_mbias.stem\n",
    "    mbias.meta['HISTORY']  = f'({datetime.now().isoformat()}) {len(biasframes)} bias frames combined.'\n",
    "    for i in range(len(biasframes)):\n",
    "        mbias.meta['HISTORY'] = f\"bias-{i+1:2d}: {biasframes[i]}\"\n",
    "    \n",
    "    # Save the output\n",
    "    hdu_mbias = fits.PrimaryHDU(data=mbias.data, header=mbias.header)\n",
    "    hdu_mbias.writeto(fpath_mbias, overwrite=True)\n",
    "    # mbias.write(fpath_mbias, overwrite=True)\n",
    "    print(f\"Done. {fpath_mbias} has been created. ({datetime.now().isoformat()})\")\n",
    "\n",
    "\n",
    "\n",
    "def make_mdark(darkframes, masterdir, key_exptime='exptime'):\n",
    "    \"\"\"\n",
    "    Create master dark frames by subtracting a master bias frame from dark frames \n",
    "    and combining the bias-subtracted dark frames for each exposure time.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    darkframes : list of pathlib.Path\n",
    "        List of file paths to the dark frames to be processed.\n",
    "    masterdir : pathlib.Path\n",
    "        Directory where the master bias frames are located and where the resulting master dark frames will be saved.\n",
    "    key_exptime : str, optional\n",
    "        Header keyword used to extract the exposure time from the FITS files. \n",
    "        Default is 'exptime'.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        The function saves the master dark frames to the specified directory \n",
    "        and does not return any value.\n",
    "        \n",
    "    Notes:\n",
    "    ------\n",
    "    - The function checks for the existence of the master bias directory and \n",
    "      ensures that it contains valid master bias frames.\n",
    "    - Dark frames are bias-subtracted using the closest-in-time master bias frame.\n",
    "    - A temporary directory is created to store intermediate bias-subtracted dark frames, \n",
    "      which is cleaned up after processing.\n",
    "    - Master dark frames are created for each unique exposure time by combining \n",
    "      the bias-subtracted dark frames using median combination with sigma clipping.\n",
    "    - Metadata is added to the resulting master dark frames, including a history \n",
    "      of the combined frames.\n",
    "    - The function prints progress and status messages during execution.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\"\"\\n================================\n",
    "Master Dark\n",
    "================================\"\"\")\n",
    "    \n",
    "    # Check the directory\n",
    "    masterdir = Path(masterdir)\n",
    "    if not masterdir.exists():\n",
    "        print(f\"Directory not found : {masterdir}\")\n",
    "        return\n",
    "    \n",
    "    # Check master bias.\n",
    "    mbiasframes = ccdp.ImageFileCollection(masterdir, glob_include=\"[!._]*.fits\").filter(imagetyp=\"Bias\")\n",
    "    if len(mbiasframes.files) == 0:\n",
    "        print(f\"No master bias found in directory: {masterdir}\")\n",
    "        return\n",
    "        \n",
    "    # Check dark frames.\n",
    "    if len(darkframes) == 0:\n",
    "        print(\"No dark frames found.\")\n",
    "        return\n",
    "\n",
    "    # Metatdata (first frame)\n",
    "    meta_dark  = fits.getheader(darkframes[0])\n",
    "    \n",
    "    # Extract observation date.\n",
    "    obsdate_jd = meta_dark[\"JD\"]\n",
    "    obsdate    = meta_dark[\"OBSDATE\"]\n",
    "\n",
    "    print(f\"\\nobs-date: {obsdate}\")\n",
    "    \n",
    "    # Load the master bias frame (Closed to the observation time)\n",
    "    jd_mbias    = mbiasframes.summary.to_pandas()[\"jd\"]\n",
    "    idx_mbias   = (jd_mbias - obsdate_jd).abs().idxmin()\n",
    "    fpath_mbias = Path(mbiasframes.files_filtered(include_path=True)[idx_mbias])\n",
    "    mbias       = CCDData.read(fpath_mbias, unit=\"adu\")\n",
    "    \n",
    "    # Temporary directory (removed after end of process)\n",
    "    TMPDIR = masterdir/'tmp' \n",
    "    TMPDIR.mkdir(parents=True, exist_ok=True)\n",
    "    funcs.clear_dir(TMPDIR)\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # Subtract master bias from dark frames\n",
    "    # -------------------------------------\n",
    "    print(f'{len(darkframes)} dark frames have been found. Subtracting master bias...')\n",
    "    for fpath_dark in darkframes: \n",
    "                           \n",
    "        fpath_bdark = TMPDIR / (fpath_dark.stem+'.bs'+fpath_dark.suffix)\n",
    "        \n",
    "        dark       = CCDData.read(fpath_dark)\n",
    "        bdark      = ccdp.subtract_bias(dark, mbias)\n",
    "        bdark.meta[\"history\"] = f\"Master bias: {fpath_mbias.name}\"\n",
    "        bdark.write(fpath_bdark, overwrite=True)\n",
    "    \n",
    "    # Collect the bias-subtracted dark frames\n",
    "    bdarkframes   = ccdp.ImageFileCollection(TMPDIR, glob_include='[!._]*.fits')\n",
    "    \n",
    "    # Get the exposure time of the dark frames\n",
    "    allexptime    = set(bdarkframes.summary[key_exptime])\n",
    "    \n",
    "    # --------------------------------------------\n",
    "    # combine master dark (for each exposure time)\n",
    "    # --------------------------------------------\n",
    "    for exptime in allexptime:\n",
    "        \n",
    "        bdarkframes_exptime = [Path(f) for f in bdarkframes.files_filtered(exptime=exptime, include_path=True)]\n",
    "        \n",
    "        # Output file name \n",
    "        fpath_mdark = masterdir/(f\"kl4040.dark.{int(round(exptime)):03d}s.comb.{obsdate}.fits\")\n",
    "        \n",
    "        # filename    = fits.getheader(bdarkframes_exptime[0])[\"irafname\"]\n",
    "        # parts       = filename.split(\".\")\n",
    "        # parts[-1]   = \"comb\"\n",
    "        # fpath_mdark = masterdir/(\".\".join(parts) + \".fits\") \n",
    "        # fpath_mdark = masterdir / f\"dark.2x2.{exptime:1.0f}.{obsdate}.comb.fits\"\n",
    "        \n",
    "        print(f'\\n{len(bdarkframes_exptime)} dark frames have been found (exptime={exptime:3.1f}s). Combining master frame...')\n",
    "        mdark = ccdp.combine(bdarkframes_exptime,\n",
    "                            method='median',\n",
    "                            sigma_clip=True,\n",
    "                            sigma_clip_low_thresh=5,\n",
    "                            sigma_clip_high_thresh=5,\n",
    "                            sigma_clip_func=np.ma.median,\n",
    "                            sigma_clip_dev_func=mad_std,\n",
    "                            mem_limit=500e6,\n",
    "                            dtype=np.float32\n",
    "                            )    \n",
    "        \n",
    "        # Add metadata\n",
    "        mdark.meta['combined'] = True\n",
    "        mdark.meta['NCOMBINE'] = len(bdarkframes_exptime)\n",
    "        # mdark.meta['jd']       = (obsdate_jd, \"Julian date\")\n",
    "        mdark.meta['imagetyp'] = \"DARK\"\n",
    "        mdark.meta['object'] = fpath_mdark.stem\n",
    "        mdark.meta['history']  = f'({datetime.now().isoformat()}) {len(bdarkframes_exptime)} dark frames combined.'\n",
    "        for i in range(len(bdarkframes_exptime)):\n",
    "            mdark.meta['history'] = f\"dark-{i+1:2d}: {bdarkframes_exptime[i]}\"\n",
    "        \n",
    "        # Save the output\n",
    "        # mdark.write(fpath_mdark, overwrite=True)\n",
    "        hdu_mdark = fits.PrimaryHDU(data=mdark.data, header=mdark.header)\n",
    "        hdu_mdark.writeto(fpath_mdark, overwrite=True)\n",
    "    \n",
    "        print(f\"Done. {fpath_mdark} has been created. ({datetime.now().isoformat()})\")\n",
    "\n",
    "    # Clear out the temporary directory\n",
    "    funcs.clear_dir(TMPDIR)\n",
    "    TMPDIR.rmdir()\n",
    "    print(f\"\\nTemporary directory {TMPDIR} has been deleted. ({datetime.now().isoformat()})\")\n",
    "\n",
    "\n",
    "\n",
    "def make_mflat(flatframes, masterdir, filtername, key_exptime=\"exptime\"):\n",
    "    \"\"\"\n",
    "    Create a master flat frame by processing a set of flat frames.\n",
    "    This function performs the following steps:\n",
    "    1. Checks for the existence of the master directory and required master bias and dark frames.\n",
    "    2. Subtracts the master bias from the flat frames.\n",
    "    3. Subtracts the master dark from the bias-subtracted flat frames.\n",
    "    4. Combines the processed flat frames into a single master flat frame using median combination.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    flatframes : list of pathlib.Path\n",
    "        List of file paths to the flat frames to be processed.\n",
    "    masterdir : str or pathlib.Path\n",
    "        Path to the directory containing the master calibration frames (bias and dark).\n",
    "    filtername : str\n",
    "        Name of the filter used for the flat frames (e.g., \"R\", \"G\", \"B\").\n",
    "    key_exptime : str, optional\n",
    "        Header keyword for the exposure time in the FITS files. Default is \"exptime\".\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        The function saves the resulting master flat frame to the specified master directory.\n",
    "    Notes:\n",
    "    ------\n",
    "    - The function assumes that the flat frames, master bias, and master dark frames are in FITS format.\n",
    "    - Temporary files are created during processing and are removed after the master flat frame is created.\n",
    "    - The resulting master flat frame is saved with a filename format: `rasa.flat.<obsdate>.<filtername>.comb.fits`.\n",
    "    Raises:\n",
    "    -------\n",
    "    FileNotFoundError:\n",
    "        If the specified master directory does not exist.\n",
    "    ValueError:\n",
    "        If no flat frames, master bias, or master dark frames are found.\n",
    "    Example:\n",
    "    --------\n",
    "    >>> from pathlib import Path\n",
    "    >>> flatframes = [Path(\"flat1.fits\"), Path(\"flat2.fits\")]\n",
    "    >>> masterdir = Path(\"/path/to/master/frames\")\n",
    "    >>> filtername = \"R\"\n",
    "    >>> make_mflat(flatframes, masterdir, filtername)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\"\"\\n================================\n",
    "Master Flat\n",
    "================================\"\"\")\n",
    "    \n",
    "    # Check directory\n",
    "    masterdir = Path(masterdir)\n",
    "    if not masterdir.exists():\n",
    "        print(f\"Directory not found : {masterdir}\")\n",
    "        return\n",
    "\n",
    "    # Check master bias.\n",
    "    mbiasframes = ccdp.ImageFileCollection(masterdir, glob_include=\"[!._]*.fits\").filter(imagetyp=\"Bias\")\n",
    "    if len(mbiasframes.files) == 0:\n",
    "        print(f\"No master bias found in directory: {masterdir}\")\n",
    "        return\n",
    "    \n",
    "    # # Check master dark.\n",
    "    # mdarkframes = ccdp.ImageFileCollection(masterdir, glob_include=\"[!._]*.fits\").filter(imagetyp=\"Dark\")\n",
    "    # if len(mdarkframes.files) == 0:\n",
    "    #     print(f\"No master bias found in directory: {masterdir}\")\n",
    "    #     return\n",
    "                \n",
    "    # Check flat frames    \n",
    "    if len(flatframes) == 0:\n",
    "        print(\"No flat frame found.\")\n",
    "        return\n",
    "    \n",
    "    # Extract observation date.\n",
    "    obsdate_jd = fits.getheader(flatframes[0])[\"j_date\"]\n",
    "    obsdate_jd = float(obsdate_jd.split()[0])\n",
    "    obsdate = Time(obsdate_jd, format=\"jd\").to_datetime().strftime(\"%Y%m%d\") \n",
    "    \n",
    "    print(f\"\\nobs-date: {obsdate}\")\n",
    "    \n",
    "    # Load the master bias frame (Closed to the observation time)\n",
    "    jd_values = (mbiasframes.summary.to_pandas())[\"j_date\"].apply(lambda x: float(x.split()[0]))\n",
    "    idx_mbias = (jd_values - obsdate_jd).abs().idxmin()\n",
    "    fpath_mbias = Path(mbiasframes.files_filtered(include_path=True)[idx_mbias])\n",
    "    mbias = CCDData.read(fpath_mbias)\n",
    "\n",
    "    # Temporary directory (removed after end of process)\n",
    "    TMPDIR = masterdir/'tmp' \n",
    "    TMPDIR.mkdir(parents=True, exist_ok=True)\n",
    "    funcs.clear_dir(TMPDIR)\n",
    "    \n",
    "    # Output file name \n",
    "    filename    = fits.getheader(flatframes[0])[\"irafname\"]\n",
    "    parts       = filename.split(\".\")\n",
    "    parts[-1]   = \"comb\"\n",
    "    fpath_mflat = masterdir/(\".\".join(parts) + \".fits\") \n",
    "    # fpath_mflat = masterdir / f\"mf.2x2.{obsdate}.{filtername}.comb.fits\"\n",
    "    \n",
    "    # -----------------------------------\n",
    "    # Subtract master bias from flat frames\n",
    "    # -----------------------------------\n",
    "    for fpath_flat in tqdm(flatframes,\n",
    "                           total=len(flatframes), \n",
    "                           desc=f'Subtracting master bias from {len(flatframes)} flat frames...'):\n",
    "        \n",
    "        fpath_bflat = TMPDIR / (fpath_flat.stem+'.bs'+fpath_flat.suffix) # Bias subtracted flat\n",
    "        \n",
    "        flat       = CCDData.read(fpath_flat, unit='adu')\n",
    "        bflat      = ccdp.subtract_bias(flat, mbias)\n",
    "        bflat.meta[\"history\"] = f\"Master bias: {fpath_mbias.name}\"\n",
    "        bflat.write(fpath_bflat, overwrite=True)\n",
    "    \n",
    "    # Collect the bias-subtracted flat frames\n",
    "    bflatframes   = ccdp.ImageFileCollection(TMPDIR, glob_include=\"[!._]*.fits\")\n",
    "    bflatframes   = [Path(f) for f in bflatframes.files_filtered(include_path=True)]\n",
    "    \n",
    "    # # Get the exposure time of the flat frames\n",
    "    # allexptime    = set(bflatframes.summary[key_exptime])\n",
    "    \n",
    "    # # Get the exposure time of the dark frames\n",
    "    # darkexptime   = set(mdarkframes.summary[key_exptime])\n",
    "    \n",
    "    # # Save bias and dark subtracted flat frames\n",
    "    # bdflatframes  = [] \n",
    "\n",
    "    # # -----------------------------------\n",
    "    # # Subtract master dark from flat frames\n",
    "    # # -----------------------------------\n",
    "    # for exptime in allexptime:\n",
    "        \n",
    "    #     # Load the master dark frame (Close obsdate and exposure time)\n",
    "    #     darkexptime_closest = min(darkexptime, key=lambda x: abs(x - exptime))\n",
    "    #     mdarkframes_exptime = mdarkframes.filter(exptime=darkexptime_closest)\n",
    "        \n",
    "    #     jd_values = (mdarkframes_exptime.summary.to_pandas())[\"jd\"]\n",
    "    #     idx_mdark = (jd_values - obsdate_jd).abs().idxmin()\n",
    "    #     fpath_mdark = Path(mdarkframes_exptime.files_filtered(include_path=True)[idx_mdark])\n",
    "    #     mdark = CCDData.read(fpath_mdark)\n",
    "\n",
    "    #     # Collect the bias-subtracted flat frames with same expsoure time\n",
    "    #     bflatframes_exptime = [Path(bflat) for bflat in bflatframes.files_filtered(exptime=exptime, include_path=True)]\n",
    "        \n",
    "    #     # subtract master dark from flat frames\n",
    "    #     for fpath_bflat in tqdm(bflatframes_exptime,\n",
    "    #                             total=len(bflatframes_exptime), \n",
    "    #                             desc=f'Subtracting master dark (exptime={exptime:3.1f}s) from {len(bflatframes_exptime)} flat frames...'):\n",
    "        \n",
    "    #         fpath_bdflat = TMPDIR / (fpath_bflat.stem+'.ds'+fpath_bflat.suffix)\n",
    "            \n",
    "    #         bflat        = CCDData.read(fpath_bflat)\n",
    "    #         bdflat       = ccdp.subtract_dark(bflat, mdark, exposure_time=key_exptime, exposure_unit=u.second)\n",
    "    #         bdflat.meta[\"history\"] = f\"Master dark: {fpath_mdark.name}\"\n",
    "    #         bdflat.write(fpath_bdflat)\n",
    "            \n",
    "    #         fpath_bflat.unlink()\n",
    "    #         bdflatframes.append(fpath_bdflat)\n",
    "    \n",
    "    # -----------------------------------\n",
    "    # Combine master flat\n",
    "    # -----------------------------------\n",
    "    print(f'\\n{len(bflatframes)} flat frames have been found (filter={filtername}). Combining master frame...')\n",
    "\n",
    "    # # average-combine (recommneded for fast-calculation)\n",
    "    # mflat = ccdp.combine(bdflatframes,\n",
    "    #                      method='average',\n",
    "    #                      scale=funcs.inv_median,\n",
    "    #                      sigma_clip=True,\n",
    "    #                      sigma_clip_low_thresh=5,\n",
    "    #                      sigma_clip_high_thresh=5,\n",
    "    #                      sigma_clip_func=np.ma.median,\n",
    "    #                      sigma_clip_dev_func=mad_std,\n",
    "    #                      mem_limit=350e6,\n",
    "    #                      dtype=np.float32\n",
    "    #                      )    \n",
    "\n",
    "    # median combine (recommended for science frames)\n",
    "    mflat = ccdp.combine(bflatframes,\n",
    "                        method='median',\n",
    "                        scale=funcs.inv_median,\n",
    "                        sigma_clip=True,\n",
    "                        sigma_clip_low_thresh=5,\n",
    "                        sigma_clip_high_thresh=5,\n",
    "                        sigma_clip_func=np.ma.median,\n",
    "                        sigma_clip_dev_func=mad_std,\n",
    "                        mem_limit=500e6,\n",
    "                        dtype=np.float32\n",
    "                        )\n",
    "\n",
    "    # Add metadata\n",
    "    mflat.meta['jd']       = (obsdate_jd, \"Julian date\") \n",
    "    mflat.meta['combined'] = True\n",
    "    mflat.meta['filter']   = filtername\n",
    "    mflat.meta['imagetyp'] = \"Flat\"\n",
    "    mflat.meta['object']   = fpath_mflat.stem\n",
    "    mflat.meta['history']  = f'{len(bflatframes)} flat frames combined at {datetime.now().isoformat()}'\n",
    "    for i in range(len(bflatframes)):\n",
    "            mflat.meta['history'] = f\"flat-{i+1:2d}: {bflatframes[i]}\"\n",
    "\n",
    "    # Save the output\n",
    "    mflat.write(fpath_mflat, overwrite=True)\n",
    "    print(f\"Master flat frame: {fpath_mflat} has been created. ({datetime.now()})\")\n",
    "\n",
    "    # delete temporary directory\n",
    "    funcs.clear_dir(TMPDIR)\n",
    "    TMPDIR.rmdir()\n",
    "    print(f\"Temporary directory {TMPDIR} has been deleted ({datetime.now().isoformat()}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d84224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import Angle, SkyCoord, GCRS, GeocentricTrueEcliptic\n",
    "from astropy.coordinates import get_body, get_sun\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "from datetime import datetime\n",
    "\n",
    "class RasaLcpyLV0:\n",
    "    \"\"\"\n",
    "    Class for updating Level-0 (raw) FITS headers in the RASA lcpy KL4040 data pipeline.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_file: str = None):\n",
    "        # set up console + optional file logging\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler()\n",
    "        handler.setFormatter(logging.Formatter(\"%(asctime)s [%(levelname)s] %(message)s\"))\n",
    "        self.logger.addHandler(handler)\n",
    "        if log_file:\n",
    "            file_h = logging.FileHandler(log_file)\n",
    "            file_h.setFormatter(handler.formatter)\n",
    "            self.logger.addHandler(file_h)\n",
    "\n",
    "    def update_header(self, fpath_fits):\n",
    "        \"\"\"\n",
    "        Open a raw FITS file, validate and update its header, then overwrite the file.\n",
    "        \"\"\"\n",
    "        fpath = Path(fpath_fits)\n",
    "        if not fpath.exists():\n",
    "            self.logger.error(f\"File not found: {fpath}\")\n",
    "            return\n",
    "\n",
    "        hdul = fits.open(fpath)\n",
    "        hdr = hdul[0].header.copy()\n",
    "\n",
    "        # ... (all the header-update logic here) ...\n",
    "\n",
    "        new_hdu = fits.PrimaryHDU(data=hdul[0].data, header=hdr)\n",
    "        new_hdu.writeto(fpath, overwrite=True)\n",
    "        self.logger.info(f\"Updated LV0 header: {fpath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef62e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.wcs import FITSFixedWarning\n",
    "import astropy.units as u\n",
    "from astropy.nddata import CCDData\n",
    "from astropy.stats import mad_std\n",
    "import ccdproc as ccdp\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import _funcs as funcs\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FITSFixedWarning)\n",
    "\n",
    "class CombMaster:\n",
    "    \"\"\"\n",
    "    Class to create master calibration frames (bias, dark, flat) for RASA lcpy KL4040.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_file: str = None):\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler()\n",
    "        handler.setFormatter(logging.Formatter(\"%(asctime)s [%(levelname)s] %(message)s\"))\n",
    "        self.logger.addHandler(handler)\n",
    "        if log_file:\n",
    "            file_h = logging.FileHandler(log_file)\n",
    "            file_h.setFormatter(handler.formatter)\n",
    "            self.logger.addHandler(file_h)\n",
    "\n",
    "    def make_mbias(self, bias_frames, master_dir):\n",
    "        \"\"\"Combine bias frames into a master bias.\"\"\"\n",
    "        # ... (implementation as before) ...\n",
    "\n",
    "    def make_mdark(self, dark_frames, master_dir, key_exptime='exptime'):\n",
    "        \"\"\"Subtract master bias and combine dark frames by exposure time.\"\"\"\n",
    "        # ... (implementation as before) ...\n",
    "\n",
    "    def make_mflat(self, flat_frames, master_dir, filter_name, key_exptime='exptime'):\n",
    "        \"\"\"Subtract bias (and dark) and combine flat frames.\"\"\"\n",
    "        # ... (implementation as before) ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a41fc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in your processing script:\n",
    "from rasa_lcpy_lv0 import RasaLcpyLV0\n",
    "from comb_master import CombMaster\n",
    "\n",
    "lv0 = RasaLcpyLV0(log_file=\"pipeline.log\")\n",
    "comb = CombMaster(log_file=\"pipeline.log\")\n",
    "\n",
    "# update headers\n",
    "lv0.update_header(\"/data/raw/image0001.fits\")\n",
    "\n",
    "# make master frames\n",
    "comb.make_mbias(bias_list, \"/data/cal/master\")\n",
    "comb.make_mdark(dark_list, \"/data/cal/master\")\n",
    "comb.make_mflat(flat_list, \"/data/cal/master\", filter_name=\"R\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d0814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mbias(biasframes, masterdir):\n",
    "    \"\"\"\n",
    "    Combine multiple bias frames into a master bias frame and save the result.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    biasframes : list of str or pathlib.Path\n",
    "        Paths to the individual bias FITS frames to be combined.\n",
    "    masterdir : str or pathlib.Path\n",
    "        Directory where the master bias frame will be saved.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Writes a FITS file named `kl4040.bias.comb.<obsdate>.fits` into masterdir.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - If biasframes is empty, the function exits without writing.\n",
    "    - Uses median combination with sigma clipping (±5σ).\n",
    "    - Adds metadata including COMBINED, NCOMBINE, IMAGETYP, OBJECT, and HISTORY.\n",
    "    \"\"\"\n",
    "    print(\"\"\"\\n================================\n",
    "Master Bias\n",
    "================================\"\"\")\n",
    "    …  # rest of original code unchanged\n",
    "\n",
    "def make_mdark(darkframes, masterdir, key_exptime='exptime'):\n",
    "    \"\"\"\n",
    "    Create master dark frames by subtracting a master bias and combining by exposure time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    darkframes : list of pathlib.Path\n",
    "        Paths to the individual dark FITS frames to process.\n",
    "    masterdir : pathlib.Path\n",
    "        Directory containing the master bias and where master darks will be saved.\n",
    "    key_exptime : str, optional\n",
    "        Header keyword for exposure time (default: 'exptime').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Writes one master dark FITS per unique exposure time `kl4040.dark.<exp>s.comb.<obsdate>.fits`.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Requires at least one master bias in masterdir (IMAGETYP='Bias').\n",
    "    - Subtracts the closest-in-time bias from each dark.\n",
    "    - Combines resulting darks with median+sigma clipping.\n",
    "    - Cleans up temporary bias-subtracted files on exit.\n",
    "    \"\"\"\n",
    "    print(\"\"\"\\n================================\n",
    "Master Dark\n",
    "================================\"\"\")\n",
    "    …  # rest of original code unchanged\n",
    "\n",
    "def make_mflat(flatframes, masterdir, filtername, key_exptime=\"exptime\"):\n",
    "    \"\"\"\n",
    "    Create a master flat by bias-subtracting and combining flat frames.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flatframes : list of pathlib.Path\n",
    "        Paths to the individual flat FITS frames to process.\n",
    "    masterdir : str or pathlib.Path\n",
    "        Directory containing master bias (and optionally dark) and where result is saved.\n",
    "    filtername : str\n",
    "        Filter identifier for naming (e.g., 'R', 'G', 'B', or 'CLEAR').\n",
    "    key_exptime : str, optional\n",
    "        Header keyword for exposure time (default: 'exptime').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Writes a FITS file named `rasa.flat.<obsdate>.<filtername>.comb.fits` into masterdir.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Checks for and uses master bias frames (IMAGETYP='Bias').\n",
    "    - (Optional dark subtraction code is commented out.)\n",
    "    - Combines bias-subtracted flats via median+sigma clipping, scaled by funcs.inv_median.\n",
    "    - Removes temporary files and reports completion.\n",
    "    \"\"\"\n",
    "    print(\"\"\"\\n================================\n",
    "Master Flat\n",
    "================================\"\"\")\n",
    "    …  # rest of original code unchanged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd29f812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import Angle, SkyCoord, GCRS, GeocentricTrueEcliptic\n",
    "from astropy.coordinates import get_body, get_sun\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "from datetime import datetime\n",
    "\n",
    "def LV0_HeaderUpdate(fpath_fits):\n",
    "    \n",
    "\n",
    "    \n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # FITS file open\n",
    "    try:\n",
    "        hdul = fits.open(fpath_fits)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"File not found: {fpath_fits}\")\n",
    "        return\n",
    "    \n",
    "    # Import header\n",
    "    hdr = hdul[0].header\n",
    "    \n",
    "    ###\n",
    "    ### (TBA) Check if the header info. is valid. \n",
    "    ###\n",
    "    \n",
    "    hdr_updated = hdr.copy()\n",
    "\n",
    "    # Updates header info.\n",
    "    hdr_updated.comments[\"LT\"]  = \"Local Time\"\n",
    "    hdr_updated.comments[\"UTC\"] = \"Universal Time Coordinated\"\n",
    "    hdr_updated[\"EXPTIME\"]  = (float(hdr[\"EXPTIME\"]), \"Exposure Time (sec)\")\n",
    "    hdr_updated[\"CCDTEMP\"]  = (float(hdr[\"CCDTEMP\"]), \"CCD Temperature (C)\")\n",
    "    hdr_updated[\"PIXSZ\"]    = (float(hdr[\"PIXSZ\"]), \"Pixel Size (um)\")\n",
    "    hdr_updated[\"JD\"]       = (float(hdr[\"JD\"]), \"Julian Date\")\n",
    "    hdr_updated[\"DATE-OBS\"] = (Time(hdr_updated[\"JD\"], format=\"jd\").isot, \"Observation Datetime\")\n",
    "    hdr_updated[\"MJD-OBS\"]  = (Time(hdr_updated[\"JD\"], format=\"jd\").mjd, \"Modified Julian Date\")\n",
    "    hdr_updated[\"FOCALLEN\"] = (float(hdr[\"FOCALLEN\"]), \"Focal Length (mm)\")\n",
    "    hdr_updated[\"APTDIA\"]   = (float(hdr[\"APTDIA\"]), \"Aperture Diameter (mm)\")\n",
    "    hdr_updated[\"FOCUS\"]    = (int(hdr[\"FOCUS\"]), \"Focal Position\")\n",
    "    hdr_updated[\"OBSERVER\"] = (hdr[\"OBSERVER\"].upper(), \"Observer\")\n",
    "    hdr_updated[\"IMAGETYP\"] = (hdr[\"IMAGETYP\"].upper(), \"Image Type (BIAS, DARK, FLAT, LIGHT)\")\n",
    "\n",
    "    # Telescope & Site coordinates\n",
    "    hdr_updated[\"RA\"]       = (Angle(hdr[\"RA\"], unit='hourangle').degree, \"Telescope Right Ascension (deg)\") if type(hdr[\"RA\"]) is str else hdr[\"RA\"]\n",
    "    hdr_updated[\"DEC\"]      = (Angle(hdr[\"DEC\"], unit='degree').degree, \"Telescope Declination (deg)\") if type(hdr[\"DEC\"]) is str else hdr[\"DEC\"]\n",
    "    hdr_updated[\"ALT\"]      = (Angle(hdr[\"ALT\"], unit='degree').degree, \"Telescope Altitude (deg)\") if type(hdr[\"ALT\"]) is str else hdr[\"ALT\"]\n",
    "    hdr_updated[\"AZ\"]       = (Angle(hdr[\"AZ\"], unit='degree').degree, \"Telescope Azimuth (deg)\") if type(hdr[\"AZ\"]) is str else hdr[\"AZ\"]\n",
    "    hdr_updated[\"LON\"]      = (-119.4, \"Site Longitude (deg)\")\n",
    "    hdr_updated[\"LAT\"]      = (37.07, \"Site Latitude (deg)\")\n",
    "    hdr_updated[\"ELEV\"]     = (1.405, \"Site Elevation (km)\")\n",
    "\n",
    "    # Additional info.\n",
    "    hdr_updated[\"BUNIT\"]    = (\"adu\", \"array data unit\")\n",
    "    hdr_updated[\"OBSERVAT\"] = \"Sierra Remote Observatories\"\n",
    "    hdr_updated[\"DETECTOR\"] = (\"FLI Camera KL4040 FI\", \"Detector Name\")\n",
    "    hdr_updated[\"FILTER\"]   = (\"CLEAR\", \"Filter Name\")\n",
    "    hdr_updated[\"OBSDATE\"]  = (Time(hdr[\"JD\"], format=\"jd\").to_datetime().strftime(\"%Y%m%d\"), \"YYYYMMD (UT)\")\n",
    "\n",
    "    hdr_updated[\"DATLEVEL\"] = (0, \"Data Process Level (0-2)\")\n",
    "    hdr_updated[\"COMBINED\"] = (False, \"Is image combined? (True/False)\")\n",
    "    hdr_updated[\"BIASCORR\"] = (False, \"Bias Corrected (True/False)\")\n",
    "    hdr_updated[\"DARKCORR\"] = (False, \"Dark Corrected (True/False)\")\n",
    "    hdr_updated[\"FLATCORR\"] = (False, \"Flat Corrected (True/False)\")\n",
    "    \n",
    "    ### Coordinates info.\n",
    "    obstime = Time(hdr_updated[\"JD\"], format=\"jd\") # observation time\n",
    "\n",
    "    coords_icrs = SkyCoord(\n",
    "        ra=hdr_updated[\"RA\"]*u.deg,\n",
    "        dec=hdr_updated[\"DEC\"]*u.deg,\n",
    "        frame='icrs'\n",
    "        )\n",
    "    coords_gcrs = coords_icrs.transform_to(GCRS(obstime=obstime))\n",
    "\n",
    "    # Galactic coordinates\n",
    "    gal = coords_icrs.galactic\n",
    "    \n",
    "    # Ecliptic coordinates\n",
    "    ecl = coords_icrs.transform_to(GeocentricTrueEcliptic(equinox=obstime))\n",
    "    \n",
    "    # Solar elongation\n",
    "    scoord_gcrs = get_sun(obstime)\n",
    "    selong = coords_gcrs.separation(scoord_gcrs)\n",
    "\n",
    "    # Lunar elongation\n",
    "    mcoord_gcrs = get_body(\"Moon\", obstime)\n",
    "    lelong = coords_gcrs.separation(mcoord_gcrs)\n",
    "    \n",
    "    hdr_updated[\"SELONG\"] = (selong.value, \"Field Solar Elongation (deg)\")\n",
    "    hdr_updated[\"MELONG\"] = (lelong.value, \"Field Lunar Elongation (deg)\")\n",
    "    hdr_updated[\"ECLAT\"]  = (ecl.lat.value, \"Field Ecliptic Latitude (deg)\")\n",
    "    hdr_updated[\"ECLON\"]  = (ecl.lon.value, \"Field Ecliptic Longitude (deg)\")\n",
    "    hdr_updated[\"GXLAT\"]  = (gal.l.value, \"Field Galactic Latitude (deg)\")\n",
    "    hdr_updated[\"GXLON\"]  = (gal.b.value, \"Field Galactic Longitude (deg)\")\n",
    "    \n",
    "    hdr_updated[\"HISTORY\"] = f\"({datetime.now().isoformat()}) Lv.0 header updated.\"\n",
    "    \n",
    "    hdul_updated = fits.PrimaryHDU(data = hdul[0].data, header=hdr_updated)\n",
    "    \n",
    "    hdul_updated.writeto(fpath_fits, overwrite=True)\n",
    "    print(f\"({datetime.now().isoformat()}) Lv.0 header updated: {fpath_fits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25683d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_lv0.py\n",
    "from rasa_lcpy_lv0 import RasaLcpyLV0\n",
    "\n",
    "def main():\n",
    "    # initialize—with optional logfile\n",
    "    lv0 = RasaLcpyLV0(log_file=\"rasa_pipeline.log\")\n",
    "\n",
    "    # update one file\n",
    "    lv0.update_header(\"/data/raw/night1/image001.fits\")\n",
    "\n",
    "    # or a whole directory\n",
    "    import glob\n",
    "    for f in glob.glob(\"/data/raw/**/*.fits\", recursive=True):\n",
    "        lv0.update_header(f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf57a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import Angle, SkyCoord, GCRS, GeocentricTrueEcliptic\n",
    "from astropy.coordinates import get_body, get_sun\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "from datetime import datetime\n",
    "\n",
    "class RasaLcpyLV0:\n",
    "    \"\"\"\n",
    "    Class for updating Level-0 (raw) FITS headers in the RASA lcpy KL4040 data pipeline.\n",
    "\n",
    "    This encapsulates metadata verification, enrichment (coordinate transforms, elongations),\n",
    "    and logging into a reusable component suitable for CLI or workflow integration.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_file: str = None):\n",
    "        \"\"\"\n",
    "        Initialize logger. If log_file is provided, logs are written to that file as well as stdout.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        log_file : str, optional\n",
    "            Path to a log file to append processing records.\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler()\n",
    "        handler.setFormatter(logging.Formatter(\"%(asctime)s [%(levelname)s] %(message)s\"))\n",
    "        self.logger.addHandler(handler)\n",
    "\n",
    "        if log_file:\n",
    "            file_h = logging.FileHandler(log_file)\n",
    "            file_h.setFormatter(handler.formatter)\n",
    "            self.logger.addHandler(file_h)\n",
    "\n",
    "    def update_header(self, fpath_fits):\n",
    "        \"\"\"\n",
    "        Open a raw FITS file, validate and update its header, then overwrite the file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fpath_fits : str or pathlib.Path\n",
    "            Path to the Level-0 FITS file to update.\n",
    "        \"\"\"\n",
    "        fpath = Path(fpath_fits)\n",
    "        if not fpath.exists():\n",
    "            self.logger.error(f\"File not found: {fpath}\")\n",
    "            return\n",
    "\n",
    "        hdul = fits.open(fpath)\n",
    "        hdr = hdul[0].header.copy()\n",
    "\n",
    "        # Core metadata fields\n",
    "        hdr.comments['LT']  = 'Local Time'\n",
    "        hdr.comments['UTC'] = 'Universal Time Coordinated'\n",
    "        hdr['EXPTIME']      = (float(hdr['EXPTIME']), 'Exposure Time (sec)')\n",
    "        hdr['CCDTEMP']      = (float(hdr['CCDTEMP']), 'CCD Temperature (C)')\n",
    "        hdr['PIXSZ']        = (float(hdr['PIXSZ']), 'Pixel Size (um)')\n",
    "        hdr['JD']           = (float(hdr['JD']), 'Julian Date')\n",
    "        hdr['DATE-OBS']     = (Time(hdr['JD'], format='jd').isot, 'Observation Datetime')\n",
    "        hdr['MJD-OBS']      = (Time(hdr['JD'], format='jd').mjd, 'Modified Julian Date')\n",
    "        hdr['FOCALLEN']     = (float(hdr['FOCALLEN']), 'Focal Length (mm)')\n",
    "        hdr['APTDIA']       = (float(hdr['APTDIA']), 'Aperture Diameter (mm)')\n",
    "        hdr['FOCUS']        = (int(hdr['FOCUS']), 'Focal Position')\n",
    "        hdr['OBSERVER']     = (hdr['OBSERVER'].upper(), 'Observer')\n",
    "        hdr['IMAGETYP']     = (hdr['IMAGETYP'].upper(), 'Image Type')\n",
    "\n",
    "        # Telescope & Site\n",
    "        for key, unit, comment in [('RA', 'hourangle', 'Telescope RA (deg)'),\n",
    "                                   ('DEC', 'degree', 'Telescope Dec (deg)'),\n",
    "                                   ('ALT', 'degree', 'Telescope Alt (deg)'),\n",
    "                                   ('AZ', 'degree', 'Telescope Az (deg)')]:\n",
    "            if isinstance(hdr[key], str):\n",
    "                hdr[key] = (Angle(hdr[key], unit=unit).degree, comment)\n",
    "        hdr['LON']   = (-119.4, 'Site Longitude (deg)')\n",
    "        hdr['LAT']   = (37.07, 'Site Latitude (deg)')\n",
    "        hdr['ELEV']  = (1.405, 'Site Elevation (km)')\n",
    "\n",
    "        # Processing flags\n",
    "        flags = ['BIASCORR', 'DARKCORR', 'FLATCORR']\n",
    "        for fl in flags:\n",
    "            hdr[fl] = (False, f'{fl.capitalize()} applied?')\n",
    "        hdr['DATLEVEL']  = (0, 'Data Level')\n",
    "        hdr['COMBINED']  = (False, 'Combined frames?')\n",
    "\n",
    "        # Coordinate enrichments\n",
    "        obstime = Time(hdr['JD'], format='jd')\n",
    "        coords = SkyCoord(ra=hdr['RA']*u.deg, dec=hdr['DEC']*u.deg, frame='icrs')\n",
    "        gcrs = coords.transform_to(GCRS(obstime=obstime))\n",
    "        gal  = coords.galactic\n",
    "        ecl  = coords.transform_to(GeocentricTrueEcliptic(equinox=obstime))\n",
    "\n",
    "        # Elongations\n",
    "        sun_gcrs  = get_sun(obstime)\n",
    "        moon_gcrs = get_body('Moon', obstime)\n",
    "        hdr['SELONG'] = (gcrs.separation(sun_gcrs).value, 'Solar elongation (deg)')\n",
    "        hdr['MELONG'] = (gcrs.separation(moon_gcrs).value, 'Lunar elongation (deg)')\n",
    "\n",
    "        # Galactic & ecliptic coords\n",
    "        hdr['GXLAT'] = (gal.b.value, 'Galactic latitude (deg)')\n",
    "        hdr['GXLON'] = (gal.l.value, 'Galactic longitude (deg)')\n",
    "        hdr['ECLAT'] = (ecl.lat.value, 'Ecliptic latitude (deg)')\n",
    "        hdr['ECLON'] = (ecl.lon.value, 'Ecliptic longitude (deg)')\n",
    "\n",
    "        hdr['HISTORY'] = f\"({datetime.now().isoformat()}) LV0 header updated.\"\n",
    "\n",
    "        # Write back\n",
    "        new_hdu = fits.PrimaryHDU(data=hdul[0].data, header=hdr)\n",
    "        new_hdu.writeto(fpath, overwrite=True)\n",
    "        self.logger.info(f\"Updated LV0 header: {fpath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056bbaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.wcs import FITSFixedWarning\n",
    "import astropy.units as u\n",
    "from astropy.nddata import CCDData\n",
    "from astropy.stats import mad_std\n",
    "import ccdproc as ccdp\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import _funcs as funcs\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FITSFixedWarning)\n",
    "\n",
    "class RasaLcpyLV0:\n",
    "    \"\"\"\n",
    "    Class for updating Level-0 (raw) FITS headers in the RASA lcpy KL4040 data pipeline.\n",
    "\n",
    "    This encapsulates metadata verification, enrichment (coordinate transforms, elongations),\n",
    "    and logging into a reusable component suitable for CLI or workflow integration.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_file: str = None):\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler()\n",
    "        handler.setFormatter(logging.Formatter(\"%(asctime)s [%(levelname)s] %(message)s\"))\n",
    "        self.logger.addHandler(handler)\n",
    "        if log_file:\n",
    "            file_h = logging.FileHandler(log_file)\n",
    "            file_h.setFormatter(handler.formatter)\n",
    "            self.logger.addHandler(file_h)\n",
    "\n",
    "    def update_header(self, fpath_fits):\n",
    "        fpath = Path(fpath_fits)\n",
    "        if not fpath.exists():\n",
    "            self.logger.error(f\"File not found: {fpath}\")\n",
    "            return\n",
    "        hdul = fits.open(fpath)\n",
    "        hdr = hdul[0].header.copy()\n",
    "        # [update logic as before...]\n",
    "        new_hdu = fits.PrimaryHDU(data=hdul[0].data, header=hdr)\n",
    "        new_hdu.writeto(fpath, overwrite=True)\n",
    "        self.logger.info(f\"Updated LV0 header: {fpath}\")\n",
    "\n",
    "class CombMaster:\n",
    "    \"\"\"\n",
    "    Class to create master calibration frames (bias, dark, flat) for RASA lcpy KL4040.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    make_mbias(bias_frames, master_dir)\n",
    "        Combine bias frames into a master bias.\n",
    "    make_mdark(dark_frames, master_dir, key_exptime='exptime')\n",
    "        Subtract master bias and combine dark frames by exposure time.\n",
    "    make_mflat(flat_frames, master_dir, filter_name, key_exptime='exptime')\n",
    "        Subtract bias, optionally dark, and combine flat frames.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_file: str = None):\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler()\n",
    "        handler.setFormatter(logging.Formatter(\"%(asctime)s [%(levelname)s] %(message)s\"))\n",
    "        self.logger.addHandler(handler)\n",
    "        if log_file:\n",
    "            file_h = logging.FileHandler(log_file)\n",
    "            file_h.setFormatter(handler.formatter)\n",
    "            self.logger.addHandler(file_h)\n",
    "\n",
    "    def make_mbias(self, bias_frames, master_dir):\n",
    "        \"\"\"\n",
    "        Combine multiple bias frames into a master bias frame and save it.\n",
    "        \"\"\"\n",
    "        self.logger.info(\"Starting master bias combination...\")\n",
    "        master_dir = Path(master_dir)\n",
    "        master_dir.mkdir(parents=True, exist_ok=True)\n",
    "        if not bias_frames:\n",
    "            self.logger.warning(\"No bias frames provided.\")\n",
    "            return\n",
    "        hdr0 = fits.getheader(bias_frames[0])\n",
    "        obsdate = hdr0.get('OBSDATE', Time(hdr0['JD'], format='jd').to_value('iso'))\n",
    "        out_name = master_dir / f\"kl4040.bias.comb.{obsdate}.fits\"\n",
    "        mbias = ccdp.combine(\n",
    "            bias_frames,\n",
    "            method='median',\n",
    "            sigma_clip=True,\n",
    "            sigma_clip_low_thresh=5,\n",
    "            sigma_clip_high_thresh=5,\n",
    "            sigma_clip_func=np.ma.median,\n",
    "            sigma_clip_dev_func=mad_std,\n",
    "            mem_limit=500e6,\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        mbias.meta.update({\n",
    "            'COMBINED': True,\n",
    "            'NCOMBINE': len(bias_frames),\n",
    "            'IMAGETYP': 'BIAS',\n",
    "            'HISTORY': f\"({datetime.now().isoformat()}) Combined {len(bias_frames)} bias frames.\" \n",
    "        })\n",
    "        fits.PrimaryHDU(data=mbias.data, header=mbias.meta).writeto(out_name, overwrite=True)\n",
    "        self.logger.info(f\"Master bias saved to {out_name}\")\n",
    "\n",
    "    def make_mdark(self, dark_frames, master_dir, key_exptime='exptime'):\n",
    "        \"\"\"\n",
    "        Create master dark frames by bias-subtracting and combining dark frames.\n",
    "        \"\"\"\n",
    "        self.logger.info(\"Starting master dark creation...\")\n",
    "        master_dir = Path(master_dir)\n",
    "        # find nearest master bias\n",
    "        mbias_coll = ccdp.ImageFileCollection(master_dir, glob_include='*.fits').filter(imagetyp='BIAS')\n",
    "        if not mbias_coll.files:\n",
    "            self.logger.error(\"No master bias found.\")\n",
    "            return\n",
    "        if not dark_frames:\n",
    "            self.logger.warning(\"No dark frames provided.\")\n",
    "            return\n",
    "        hdr0 = fits.getheader(dark_frames[0])\n",
    "        obs_jd = hdr0['JD']\n",
    "        # select closest bias\n",
    "        jd_series = mbias_coll.summary['jd'].astype(float)\n",
    "        idx = (abs(jd_series - obs_jd)).idxmin()\n",
    "        bias_path = Path(mbias_coll.files_filtered(include_path=True)[idx])\n",
    "        mbias = CCDData.read(bias_path, unit='adu')\n",
    "        tmp = master_dir / 'tmp'\n",
    "        funcs.clear_dir(tmp)\n",
    "        tmp.mkdir(parents=True, exist_ok=True)\n",
    "        # subtract bias\n",
    "        for d in dark_frames:\n",
    "            dark = CCDData.read(d, unit='adu')\n",
    "            bdark = ccdp.subtract_bias(dark, mbias)\n",
    "            bdark.meta['history'] = f\"Bias: {bias_path.name}\"\n",
    "            bdark.write(tmp / d.name, overwrite=True)\n",
    "        bdcoll = ccdp.ImageFileCollection(tmp, glob_include='*.fits')\n",
    "        exposures = set(bdcoll.summary[key_exptime])\n",
    "        for exp in exposures:\n",
    "            group = [Path(f) for f in bdcoll.files_filtered(**{key_exptime:exp}, include_path=True)]\n",
    "            out_dark = master_dir / f\"kl4040.dark.{int(round(exp))}s.comb.{hdr0['OBSDATE']}.fits\"\n",
    "            mdark = ccdp.combine(group, method='median', sigma_clip=True,\n",
    "                                 sigma_clip_low_thresh=5, sigma_clip_high_thresh=5,\n",
    "                                 sigma_clip_func=np.ma.median, sigma_clip_dev_func=mad_std,\n",
    "                                 mem_limit=500e6, dtype=np.float32)\n",
    "            mdark.meta.update({'COMBINED': True,'NCOMBINE': len(group),'IMAGETYP':'DARK',\n",
    "                               'history':f\"Combined {len(group)} darks at {datetime.now().isoformat()}\"})\n",
    "            fits.PrimaryHDU(data=mdark.data, header=mdark.meta).writeto(out_dark, overwrite=True)\n",
    "            self.logger.info(f\"Master dark saved to {out_dark}\")\n",
    "        funcs.clear_dir(tmp)\n",
    "        tmp.rmdir()\n",
    "        self.logger.info(\"Temporary files cleaned.\")\n",
    "\n",
    "    def make_mflat(self, flat_frames, master_dir, filter_name, key_exptime='exptime'):\n",
    "        \"\"\"\n",
    "        Create a master flat frame by subtracting bias (and dark) and combining flats.\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Starting master flat for filter {filter_name}...\")\n",
    "        master_dir = Path(master_dir)\n",
    "        if not flat_frames:\n",
    "            self.logger.warning(\"No flat frames provided.\")\n",
    "            return\n",
    "        hdr0 = fits.getheader(flat_frames[0])\n",
    "        obs_jd = float(hdr0['j_date'].split()[0])\n",
    "        obsdate = Time(obs_jd, format='jd').to_datetime().strftime('%Y%m%d')\n",
    "        # load bias\n",
    "        mbias_coll = ccdp.ImageFileCollection(master_dir, glob_include='*.fits').filter(imagetyp='BIAS')\n",
    "        jd_series = mbias_coll.summary['jd'].astype(float)\n",
    "        idx = (abs(jd_series - obs_jd)).idxmin()\n",
    "        mbias = CCDData.read(Path(mbias_coll.files_filtered(include_path=True)[idx]), unit='adu')\n",
    "        tmp = master_dir / 'tmp'\n",
    "        funcs.clear_dir(tmp)\n",
    "        tmp.mkdir(parents=True, exist_ok=True)\n",
    "        # subtract bias\n",
    "        for f in flat_frames:\n",
    "            flat = CCDData.read(f, unit='adu')\n",
    "            bflat = ccdp.subtract_bias(flat, mbias)\n",
    "            bflat.meta['history'] = f\"Bias: {mbias.meta.get('object','') }\"\n",
    "            bflat.write(tmp / f.name, overwrite=True)\n",
    "        bflist = list((ccdp.ImageFileCollection(tmp, glob_include='*.fits').files_filtered(include_path=True)))\n",
    "        out_flat = master_dir / f\"kl4040.flat.{filter_name}.{obsdate}.comb.fits\"\n",
    "        mflat = ccdp.combine([Path(p) for p in bflist], method='median', scale=funcs.inv_median,\n",
    "                             sigma_clip=True, sigma_clip_low_thresh=5, sigma_clip_high_thresh=5,\n",
    "                             sigma_clip_func=np.ma.median, sigma_clip_dev_func=mad_std,\n",
    "                             mem_limit=500e6, dtype=np.float32)\n",
    "        mflat.meta.update({'COMBINED': True,'FILTER':filter_name,'IMAGETYP':'Flat',\n",
    "                           'history':f\"Combined {len(bflist)} flats at {datetime.now().isoformat()}\"})\n",
    "        fits.PrimaryHDU(data=mflat.data, header=mflat.meta).writeto(out_flat, overwrite=True)\n",
    "        funcs.clear_dir(tmp)\n",
    "        tmp.rmdir()\n",
    "        self.logger.info(f\"Master flat saved to {out_flat}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfa4f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.wcs import FITSFixedWarning\n",
    "import astropy.units as u\n",
    "from astropy.nddata import CCDData\n",
    "from astropy.stats import mad_std\n",
    "import ccdproc as ccdp\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import _funcs as funcs\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FITSFixedWarning)\n",
    "\n",
    "class CombMaster:\n",
    "    \"\"\"\n",
    "    Class to create master calibration frames (bias, dark, flat) for RASA lcpy KL4040.\n",
    "\n",
    "    Provides methods to combine raw calibration frames into master frames,\n",
    "    with automated metadata handling, logging, and temporary file management.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_file: str = None):\n",
    "        \"\"\"\n",
    "        Initialize CombMaster with optional file logging.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        log_file : str, optional\n",
    "            Path to a log file where processing messages are appended. If None,\n",
    "            logging will only be output to stdout.\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler()\n",
    "        handler.setFormatter(logging.Formatter(\"%(asctime)s [%(levelname)s] %(message)s\"))\n",
    "        self.logger.addHandler(handler)\n",
    "        if log_file:\n",
    "            file_h = logging.FileHandler(log_file)\n",
    "            file_h.setFormatter(handler.formatter)\n",
    "            self.logger.addHandler(file_h)\n",
    "\n",
    "    def make_mbias(self, bias_frames, master_dir):\n",
    "        \"\"\"\n",
    "        Combine multiple bias frames into a single master bias frame.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        bias_frames : list of str or pathlib.Path\n",
    "            Paths to individual raw bias FITS frames to combine.\n",
    "        master_dir : str or pathlib.Path\n",
    "            Directory where the master bias file will be saved. Created if it does not exist.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pathlib.Path or None\n",
    "            Path to the generated master bias FITS file, or None if no bias_frames supplied.\n",
    "\n",
    "        Side Effects\n",
    "        ------------\n",
    "        - Writes a FITS file named 'kl4040.bias.comb.<obsdate>.fits' in master_dir.\n",
    "        - Logs progress and any errors.\n",
    "        \"\"\"\n",
    "        self.logger.info(\"Starting master bias combination...\")\n",
    "        master_dir = Path(master_dir)\n",
    "        master_dir.mkdir(parents=True, exist_ok=True)\n",
    "        if not bias_frames:\n",
    "            self.logger.warning(\"No bias frames provided.\")\n",
    "            return None\n",
    "        hdr0 = fits.getheader(bias_frames[0])\n",
    "        obsdate = hdr0.get('OBSDATE', Time(hdr0['JD'], format='jd').to_value('iso'))\n",
    "        out_name = master_dir / f\"kl4040.bias.comb.{obsdate}.fits\"\n",
    "        mbias = ccdp.combine(\n",
    "            bias_frames,\n",
    "            method='median',\n",
    "            sigma_clip=True,\n",
    "            sigma_clip_low_thresh=5,\n",
    "            sigma_clip_high_thresh=5,\n",
    "            sigma_clip_func=np.ma.median,\n",
    "            sigma_clip_dev_func=mad_std,\n",
    "            mem_limit=500e6,\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        mbias.meta.update({\n",
    "            'COMBINED': True,\n",
    "            'NCOMBINE': len(bias_frames),\n",
    "            'IMAGETYP': 'BIAS',\n",
    "            'HISTORY': f\"({datetime.now().isoformat()}) Combined {len(bias_frames)} bias frames.\" \n",
    "        })\n",
    "        fits.PrimaryHDU(data=mbias.data, header=mbias.meta).writeto(out_name, overwrite=True)\n",
    "        self.logger.info(f\"Master bias saved to {out_name}\")\n",
    "        return out_name\n",
    "\n",
    "    def make_mdark(self, dark_frames, master_dir, key_exptime='exptime'):\n",
    "        \"\"\"\n",
    "        Create master dark frames by subtracting a master bias and combining per exposure time.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dark_frames : list of str or pathlib.Path\n",
    "            Paths to raw dark FITS frames for processing.\n",
    "        master_dir : str or pathlib.Path\n",
    "            Directory containing master bias and where master dark files will be saved.\n",
    "        key_exptime : str, optional\n",
    "            Header keyword for exposure time in dark frames (default 'exptime').\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of pathlib.Path\n",
    "            Paths to generated master dark FITS files for each unique exposure time.\n",
    "\n",
    "        Side Effects\n",
    "        ------------\n",
    "        - Reads master bias from master_dir (closest in JD to first dark frame).\n",
    "        - Writes master dark FITS files named 'kl4040.dark.<exp>s.comb.<obsdate>.fits'.\n",
    "        - Cleans up temporary bias-subtracted dark files.\n",
    "        - Logs progress and errors.\n",
    "        \"\"\"\n",
    "        self.logger.info(\"Starting master dark creation...\")\n",
    "        master_dir = Path(master_dir)\n",
    "        mbias_coll = ccdp.ImageFileCollection(master_dir, glob_include='*.fits').filter(imagetyp='BIAS')\n",
    "        if not mbias_coll.files:\n",
    "            self.logger.error(\"No master bias found.\")\n",
    "            return []\n",
    "        if not dark_frames:\n",
    "            self.logger.warning(\"No dark frames provided.\")\n",
    "            return []\n",
    "        hdr0 = fits.getheader(dark_frames[0])\n",
    "        obs_jd = hdr0['JD']\n",
    "        jd_series = mbias_coll.summary['jd'].astype(float)\n",
    "        idx = (abs(jd_series - obs_jd)).idxmin()\n",
    "        bias_path = Path(mbias_coll.files_filtered(include_path=True)[idx])\n",
    "        mbias = CCDData.read(bias_path, unit='adu')\n",
    "        tmp = master_dir / 'tmp'\n",
    "        funcs.clear_dir(tmp)\n",
    "        tmp.mkdir(parents=True, exist_ok=True)\n",
    "        # Subtract bias\n",
    "        for d in dark_frames:\n",
    "            dark = CCDData.read(d, unit='adu')\n",
    "            bdark = ccdp.subtract_bias(dark, mbias)\n",
    "            bdark.meta['history'] = f\"Bias: {bias_path.name}\"\n",
    "            bdark.write(tmp / Path(d).name, overwrite=True)\n",
    "        bdcoll = ccdp.ImageFileCollection(tmp, glob_include='*.fits')\n",
    "        exposures = set(bdcoll.summary[key_exptime])\n",
    "        out_files = []\n",
    "        for exp in exposures:\n",
    "            group = [Path(f) for f in bdcoll.files_filtered(**{key_exptime:exp}, include_path=True)]\n",
    "            out_dark = master_dir / f\"kl4040.dark.{int(round(exp))}s.comb.{hdr0['OBSDATE']}.fits\"\n",
    "            mdark = ccdp.combine(group, method='median', sigma_clip=True,\n",
    "                                 sigma_clip_low_thresh=5, sigma_clip_high_thresh=5,\n",
    "                                 sigma_clip_func=np.ma.median, sigma_clip_dev_func=mad_std,\n",
    "                                 mem_limit=500e6, dtype=np.float32)\n",
    "            mdark.meta.update({'COMBINED': True,'NCOMBINE': len(group),'IMAGETYP':'DARK',\n",
    "                               'HISTORY':f\"Combined {len(group)} darks at {datetime.now().isoformat()}\"})\n",
    "            fits.PrimaryHDU(data=mdark.data, header=mdark.meta).writeto(out_dark, overwrite=True)\n",
    "            self.logger.info(f\"Master dark saved to {out_dark}\")\n",
    "            out_files.append(out_dark)\n",
    "        funcs.clear_dir(tmp)\n",
    "        tmp.rmdir()\n",
    "        self.logger.info(\"Temporary files cleaned.\")\n",
    "        return out_files\n",
    "\n",
    "    def make_mflat(self, flat_frames, master_dir, filter_name, key_exptime='exptime'):\n",
    "        \"\"\"\n",
    "        Generate a master flat frame by subtracting bias (and optionally dark) and combining flats.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        flat_frames : list of str or pathlib.Path\n",
    "            Paths to raw flat FITS frames for processing.\n",
    "        master_dir : str or pathlib.Path\n",
    "            Directory containing master bias/dark and where the master flat is saved.\n",
    "        filter_name : str\n",
    "            Filter identifier (e.g., 'R', 'G', 'B') used in naming the output.\n",
    "        key_exptime : str, optional\n",
    "            Header keyword for exposure time in flat frames (default 'exptime').\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pathlib.Path or None\n",
    "            Path to the generated master flat FITS file, or None if failure.\n",
    "\n",
    "        Side Effects\n",
    "        ------------\n",
    "        - Reads master bias from master_dir (closest in JD to first flat frame).\n",
    "        - Writes master flat named 'kl4040.flat.<filter>.<obsdate>.comb.fits'.\n",
    "        - Cleans up any temporary files.\n",
    "        - Logs all steps.\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Starting master flat for filter {filter_name}...\")\n",
    "        master_dir = Path(master_dir)\n",
    "        if not flat_frames:\n",
    "            self.logger.warning(\"No flat frames provided.\")\n",
    "            return None\n",
    "        hdr0 = fits.getheader(flat_frames[0])\n",
    "        obs_jd = float(hdr0['j_date'].split()[0])\n",
    "        obsdate = Time(obs_jd, format='jd').to_datetime().strftime('%Y%m%d')\n",
    "        mbias_coll = ccdp.ImageFileCollection(master_dir, glob_include='*.fits').filter(imagetyp='BIAS')\n",
    "        jd_series = mbias_coll.summary['jd'].astype(float)\n",
    "        idx = (abs(jd_series - obs_jd)).idxmin()\n",
    "        mbias = CCDData.read(Path(mbias_coll.files_filtered(include_path=True)[idx]), unit='adu')\n",
    "        tmp = master_dir / 'tmp'\n",
    "        funcs.clear_dir(tmp)\n",
    "        tmp.mkdir(parents=True, exist_ok=True)\n",
    "        # Subtract bias\n",
    "        for f in flat_frames:\n",
    "            flat = CCDData.read(f, unit='adu')\n",
    "            bflat = ccdp.subtract_bias(flat, mbias)\n",
    "            bflat.meta['history'] = f\"Bias: {mbias.meta.get('object','')}\"\n",
    "            bflat.write(tmp / Path(f).name, overwrite=True)\n",
    "        bflist = list((ccdp.ImageFileCollection(tmp, glob_include='*.fits').files_filtered(include_path=True)))\n",
    "        out_flat = master_dir / f\"kl4040.flat.{filter_name}.{obsdate}.comb.fits\"\n",
    "        mflat = ccdp.combine([Path(p) for p in bflist], method='median', scale=funcs.inv_median,\n",
    "                             sigma_clip=True, sigma_clip_low_thresh=5, sigma_clip_high_thresh=5,\n",
    "                             sigma_clip_func=np.ma.median, sigma_clip_dev_func=mad_std,\n",
    "                             mem_limit=500e6, dtype=np.float32)\n",
    "        mflat.meta.update({'COMBINED': True,'FILTER':filter_name,'IMAGETYP':'FLAT',\n",
    "                           'HISTORY':f\"Combined {len(bflist)} flats at {datetime.now().isoformat()}\"})\n",
    "        fits.PrimaryHDU(data=mflat.data, header=mflat.meta).writeto(out_flat, overwrite=True)\n",
    "        funcs.clear_dir(tmp)\n",
    "        tmp.rmdir()\n",
    "        self.logger.info(f\"Master flat saved to {out_flat}\")\n",
    "        return out_flat\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solopy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
